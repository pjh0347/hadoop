{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Machine Learning Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- Linear Algebra\n",
    "  - Vector\n",
    "  - Matrix\n",
    "- Statistics\n",
    "  - Correlation\n",
    "  - Hypothesis Testing\n",
    "  - Summarizer\n",
    "- Feature Engineering\n",
    "  - Polynomial Expansion\n",
    "  - Dimensionality Reduction\n",
    "    - Principal Component Analysis\n",
    "- Estimators (Models)\n",
    "  - Regression\n",
    "    - Linear Regression\n",
    "    - Generalized Linear Regression\n",
    "  - Classification\n",
    "    - Logistic Regression\n",
    "    - Linear Support Vector Machine Classifier\n",
    "    - Decision Tree Classifier\n",
    "    - Random Forest Classifier\n",
    "    - Gradient-Boosted Tree Classifier\n",
    "    - Naive Bayes Classifier\n",
    "    - Multilayer Perceptron Classifier\n",
    "  - Clustering (pyspark.ml.clustering module)\n",
    "    - K-means\n",
    "    - Bisecting K-means\n",
    "    - Gaussian Mixture Model\n",
    "    - Latent Dirichlet Allocation\n",
    "  - Anomaly Detection\n",
    "    - Gaussian Distribution\n",
    "    - Mutivariate Gaussian Distribution\n",
    "  - Recommendation\n",
    "    - Alternating Least Squares (pyspark.ml.recommendation module)\n",
    "    - Frequent Pattern Mining (pyspark.ml.fpm module)\n",
    "- Model Evaluation\n",
    "  - Metrics\n",
    "  - Cross Validation\n",
    "  - Hyperparameter Tuning\n",
    "  - Learning Curve\n",
    "  - Validation Curve\n",
    "- Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[4]\") \\\n",
    "                    .appName(\"spark MLlib tutorial\") \\\n",
    "                    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "- pyspark.ml.linalg module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dense & sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0,2.0]\n",
      "[4.0,6.0]\n",
      "[3.0,8.0]\n",
      "[3.0,2.0]\n",
      "[-1.0,0.0]\n",
      "[0.5,1.0]\n",
      "[1.0,0.0]\n",
      "[-1.0,-2.0]\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "v = Vectors.dense([1.0, 2.0])\n",
    "u = Vectors.sparse(2, [(0, 3.0), (1, 4.0)])\n",
    "\n",
    "print u - v\n",
    "print u + v\n",
    "print v * u\n",
    "print u / v\n",
    "print v - 2\n",
    "print v / 2\n",
    "print v % 2\n",
    "print -v\n",
    "\n",
    "print type(v.toArray())\n",
    "print type(v.values)\n",
    "\n",
    "# TypeError: unsupported operand type(s) for /: 'SparseVector' and 'int'\n",
    "#print u / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dot product\n",
    "- Compute the dot product of two Vectors.\n",
    "- Equivalent to calling `numpy.dot` of the two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense.dot(SparseVector(2, [0, 1], [2., 1.])) :  4.0\n",
      "dense.dot(range(1, 3)) :  5.0\n",
      "dense.dot(np.array(range(1, 3))) :  5.0\n",
      "dense.dot(np.reshape([1., 2., 3., 4.], (2, 2))) :  [ 7. 10.]\n",
      "sparse.indices :  [1 3]\n",
      "sparse.size :  4\n",
      "sparse2.indices :  [2]\n",
      "sparse2.size :  4\n",
      "25.0\n",
      "22.0\n",
      "0.0\n",
      "[22. 22.]\n"
     ]
    }
   ],
   "source": [
    "dense = DenseVector([1.0, 2.0])\n",
    "print \"dense.dot(SparseVector(2, [0, 1], [2., 1.])) : \", dense.dot(SparseVector(2, [0, 1], [2., 1.]))\n",
    "print \"dense.dot(range(1, 3)) : \", dense.dot(range(1, 3))\n",
    "print \"dense.dot(np.array(range(1, 3))) : \", dense.dot(np.array(range(1, 3)))\n",
    "print \"dense.dot(np.reshape([1., 2., 3., 4.], (2, 2))) : \", dense.dot(np.reshape([1., 2., 3., 4.], (2, 2)))\n",
    "#print dense.dot([1.,]) # dimension mismatch\n",
    "#print dense.dot(np.reshape([1., 2., 3.], (3, 1), order='F')) # dimension mismatch\n",
    "\n",
    "sparse = SparseVector(4, [1, 3], [3.0, 4.0])\n",
    "sparse2 = SparseVector(4, [2], [1.0])\n",
    "print \"sparse.indices : \", sparse.indices\n",
    "print \"sparse.size : \", sparse.size\n",
    "print \"sparse2.indices : \", sparse2.indices\n",
    "print \"sparse2.size : \", sparse2.size\n",
    "print sparse.dot(sparse)\n",
    "print sparse.dot([1.0, 2.0, 3.0, 4.0])\n",
    "print sparse.dot(sparse2)\n",
    "print sparse.dot(np.array([[1, 1], [2, 2], [3, 3], [4, 4]]))\n",
    "#print a.dot([1., 2., 3.]) # dimension mismatch\n",
    "#print a.dot(np.array([1., 2.])) # dimension mismatch\n",
    "#print a.dot(DenseVector([1., 2.])) # dimension mismatch\n",
    "#print a.dot(np.zeros((3, 2))) # dimension mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = DenseVector([1.0, 2.0])\n",
    "sparse = SparseVector(2, [0, 1], [1.0, 2.0])\n",
    "assert(dense.values.tolist()==sparse.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### norm\n",
    "- L1, L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7416573867739413\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "v = DenseVector([0, -1, 2, -3])\n",
    "print v.norm(2)\n",
    "print v.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4031242374328485\n",
      "6.40312423743\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "v = DenseVector([4, 5])\n",
    "print v.norm(2)\n",
    "print math.sqrt(4**2 + 5**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "v = DenseVector([4, 5])\n",
    "print v.norm(1)\n",
    "print abs(4 + 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squared distance\n",
    "- Squared Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dense1 = DenseVector([1., 2.])\n",
    "dense2 = np.array([2., 1.])\n",
    "dense3 = [2., 1.]\n",
    "sparse1 = SparseVector(2, [0, 1], [2., 1.])\n",
    "\n",
    "print dense1.squared_distance(dense1)\n",
    "print dense1.squared_distance(dense2)\n",
    "print dense1.squared_distance(dense3)\n",
    "print dense1.squared_distance(sparse1)\n",
    "#dense1.squared_distance([1.,]) # dimension mismatch\n",
    "#dense1.squared_distance(SparseVector(1, [0,], [1.,])) # dimension mismatch\n",
    "\n",
    "print (1-2)**2 + (2-1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[0., 3., 6.],\n",
      "             [1., 4., 7.],\n",
      "             [2., 5., 8.]])\n",
      "DenseMatrix([[0., 1., 2.],\n",
      "             [3., 4., 5.],\n",
      "             [6., 7., 8.]])\n",
      "DenseMatrix([[0., 3., 6.],\n",
      "             [1., 4., 7.],\n",
      "             [2., 5., 8.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Matrices\n",
    "from pyspark.ml.linalg import SparseMatrix\n",
    "from pyspark.ml.linalg import DenseMatrix\n",
    "\n",
    "dense = DenseMatrix(3, 3, range(9))\n",
    "print dense\n",
    "\n",
    "dense2 = DenseMatrix(3, 3, range(9), isTransposed=True)\n",
    "print dense2\n",
    "\n",
    "dense3 = Matrices.dense(3, 3, range(9))\n",
    "print dense3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "- pyspark.ml.stat module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "%matplotlib inline\n",
    "\n",
    "data = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n",
    "        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n",
    "        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n",
    "        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "def plot_heatmap(pandas_df):\n",
    "    ndarray = pandas_df.to_numpy()\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    #plt.title('Pearson correlation matrix')\n",
    "    heatmap = plt.pcolor(ndarray)\n",
    "    y_len, x_len = ndarray.shape\n",
    "    for y in range(y_len):\n",
    "        for x in range(x_len):\n",
    "            plt.text(x + 0.5, y + 0.5, '%.4f' % ndarray[y, x],\n",
    "                     horizontalalignment='center',\n",
    "                     verticalalignment='center')\n",
    "    plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pearson\n",
    "- Requirements for Pearson's correlation coefficient\n",
    "  - Scale of measurement should be interval or ratio\n",
    "  - Variables should be approximately normally distributed\n",
    "  - The association should be linear\n",
    "  - There should be no outliers in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "population\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\rho _{X,Y}={\\frac {\\operatorname {cov} (X,Y)}{\\sigma _{X}\\sigma _{Y}}}}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "{\\displaystyle r_{xy}={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{{\\sqrt {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}{\\sqrt {\\sum _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}}}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pearson(features): matrix (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400471</td>\n",
       "      <td>0.913596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2         3\n",
       "0  1.000000  0.055641  NaN  0.400471\n",
       "1  0.055641  1.000000  NaN  0.913596\n",
       "2       NaN       NaN  1.0       NaN\n",
       "3  0.400471  0.913596  NaN  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = Correlation.corr(df, \"features\", method=\"pearson\")\n",
    "\n",
    "result.printSchema()\n",
    "\n",
    "result_array = result.head()['pearson(features)'].toArray()\n",
    "pandas_df = pd.DataFrame(result_array)\n",
    "display(pandas_df)\n",
    "\n",
    "plot_heatmap(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spearman(features): matrix (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2         3\n",
       "0  1.000000  0.105409  NaN  0.400000\n",
       "1  0.105409  1.000000  NaN  0.948683\n",
       "2       NaN       NaN  1.0       NaN\n",
       "3  0.400000  0.948683  NaN  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = Correlation.corr(df, \"features\", method=\"spearman\")\n",
    "\n",
    "result.printSchema()\n",
    "\n",
    "result_array = result.head()['spearman(features)'].toArray()\n",
    "pandas_df = pd.DataFrame(result_array)\n",
    "display(pandas_df)\n",
    "\n",
    "plot_heatmap(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson’s Chi-squared Test\n",
    "- Independence test for every feature against the label.\n",
    "- degreesOfFreedom : the number of values in the final calculation of a statistic that are free to vary. (k-1)\n",
    "- statistics : 검정 통계량은 표본 데이터에서 계산되어 가설 검정에 사용되는 랜덤 변수입니다. 검정 통계량을 사용하여 귀무 가설의 기각 여부를 확인할 수 있습니다. 검정 통계량은 데이터를 귀무 가설 하에서 기대되는 값과 비교합니다. 검정 통계량은 p-값을 계산하기 위해 사용됩니다. 가설 검정마다 귀무 가설에서 가정된 확률 모형을 기반으로 각기 다른 검정 통계량을 사용합니다.\n",
    "  - 카이-제곱 검정 통계량\n",
    "\n",
    "    $\n",
    "\\begin{equation}\n",
    "{\\displaystyle E_{i} = n {\\sum _{i=1}^{k}{p_{i}}} }\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "    $\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\chi ^{2} = {\\sum _{i=1}^{k}{\\frac {(O_{i}-E_{i})^{2}} {E_{i}} }}}\n",
    "\\end{equation}\n",
    "$\n",
    "    - n : 샘플 수\n",
    "    - k : 구별 범주의 수\n",
    "    - p$_{i}$ : i번째 범주에 대한 검정 비율\n",
    "    - O$_{i}$ : i번째 범주에 대한 관측값\n",
    "    - E$_{i}$ : i번째 범주에 대한 기대값  \n",
    "\n",
    "\n",
    "| _            | A   | B   | C   | D   | Total |\n",
    "|--------------|-----|-----|-----|-----|-------|\n",
    "| White collar | 90  | 60  | 104 | 95  | 349   |\n",
    "| Blue collar  | 30  | 50  | 51  | 20  | 151   |\n",
    "| No collar    | 30  | 40  | 45  | 35  | 150   |\n",
    "| Total        | 150 | 150 | 200 | 150 | 650   |\n",
    "\n",
    "$150\\times\\frac{349}{650} \\approx 80.54$\n",
    "\n",
    "$\\frac{\\left(\\text{observed}-\\text{expected}\\right)^2}{\\text{expected}} = \\frac{\\left(90-80.54\\right)^2}{80.54} \\approx 1.11$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pValues: vector (nullable = true)\n",
      " |-- degreesOfFreedom: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = false)\n",
      " |-- statistics: vector (nullable = true)\n",
      "\n",
      "+--------------------------------------------+----------------+-------------+\n",
      "|pValues                                     |degreesOfFreedom|statistics   |\n",
      "+--------------------------------------------+----------------+-------------+\n",
      "|[0.3062189184132784,0.01430587843542952,1.0]|[5, 1, 0]       |[6.0,6.0,0.0]|\n",
      "+--------------------------------------------+----------------+-------------+\n",
      "\n",
      "Independence (fail to reject null hypotheses)\n",
      "Not independence (reject null hypotheses)\n",
      "Independence (fail to reject null hypotheses)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "data = [[0, Vectors.dense([0, 10, 1])],\n",
    "        [0, Vectors.dense([1, 10, 1])],\n",
    "        [0, Vectors.dense([2, 10, 1])],\n",
    "        [1, Vectors.dense([3, 11, 1])],\n",
    "        [1, Vectors.dense([4, 11, 1])],\n",
    "        [1, Vectors.dense([5, 11, 1])]]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"label\", \"features\"])\n",
    "\n",
    "result = ChiSquareTest.test(df, \"features\", \"label\")\n",
    "\n",
    "result.printSchema()\n",
    "result.show(truncate=False)\n",
    "\n",
    "null_hypotheses = 'Independence'\n",
    "alternative_hypotheses = 'Not independence'\n",
    "significance_level = 0.05\n",
    "pValues = result.head().pValues\n",
    "\n",
    "for pValue in pValues:\n",
    "    if pValue <= significance_level:\n",
    "        print \"{} (reject null hypotheses)\".format(alternative_hypotheses)\n",
    "    else:\n",
    "        print \"{} (fail to reject null hypotheses)\".format(null_hypotheses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature1\n",
    "\n",
    "| _     | 0 | 1 | 2 | 3 | 4 | 5 | Total |\n",
    "|-------|---|---|---|---|---|---|-------|\n",
    "| 0     | 1 | 1 | 1 | 0 | 0 | 0 | 3     |\n",
    "| 1     | 0 | 0 | 0 | 1 | 1 | 1 | 3     |\n",
    "| Total | 1 | 1 | 1 | 1 | 1 | 1 | 6     |\n",
    "\n",
    "모든 셀의 기댓값은 $1\\times\\frac{3}{6} = 0.5$\n",
    "\n",
    "$\\frac{\\left(1-0.5\\right)^2}{0.5} = 0.5$ => 6개\n",
    "\n",
    "$\\frac{\\left(0-0.5\\right)^2}{0.5} = 0.5$ => 6개\n",
    "\n",
    "총 합은 : 0.5 * 12 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kolmogorov Smirnov (콜모고로프-스미르노프) Test\n",
    "- Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pValue: double (nullable = false)\n",
      " |-- statistic: double (nullable = false)\n",
      "\n",
      "+------------------+--------------------+\n",
      "|pValue            |statistic           |\n",
      "+------------------+--------------------+\n",
      "|0.4925762238666973|0.026155067322961745|\n",
      "+------------------+--------------------+\n",
      "\n",
      "The sample data comes from normal distribution (fail to reject null hypotheses)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.stat import KolmogorovSmirnovTest\n",
    "\n",
    "mean = 0.0\n",
    "stdev = 1.0\n",
    "variance = stdev**2\n",
    "size = 1000\n",
    "sample = np.random.normal(mean, stdev, size)\n",
    "pandas_df = pd.DataFrame(sample, columns=['sample'])\n",
    "data = spark.createDataFrame(pandas_df, ['sample'])\n",
    "\n",
    "result = KolmogorovSmirnovTest.test(data, 'sample', 'norm', mean, variance)\n",
    "\n",
    "result.printSchema()\n",
    "result.show(truncate=False)\n",
    "\n",
    "null_hypotheses = 'The sample data comes from normal distribution'\n",
    "alternative_hypotheses = 'The sample data does not comes from normal distribution'\n",
    "significance_level = 0.05\n",
    "pValue = result.head().pValue\n",
    "if pValue <= significance_level:\n",
    "    print \"{} (reject null hypotheses)\".format(alternative_hypotheses)\n",
    "else:\n",
    "    print \"{} (fail to reject null hypotheses)\".format(null_hypotheses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean: a vector that contains the coefficient-wise mean.\n",
    "- variance: a vector that contains the coefficient-wise variance.\n",
    "- count: the count of all vectors seen.\n",
    "- numNonzeros: a vector with the number of non-zeros for each coefficients\n",
    "- max: the maximum for each coefficient.\n",
    "- min: the minimum for each coefficient.\n",
    "- normL2: the Euclidean norm for each coefficient.\n",
    "- normL1: the L1 norm of each coefficient (sum of the absolute values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+\n",
      "|aggregate_metrics(features, weight)                                           |\n",
      "+------------------------------------------------------------------------------+\n",
      "|[[1.3333333333333333,2.0,1.0], 2, [1.0,2.0,1.0], [2.0,2.0,1.0], [2.0,3.0,1.5]]|\n",
      "+------------------------------------------------------------------------------+\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|aggregate_metrics(features, 1.0)                                |\n",
      "+----------------------------------------------------------------+\n",
      "|[[2.5,2.0,1.0], 4, [1.0,2.0,1.0], [4.0,2.0,1.0], [10.0,8.0,4.0]]|\n",
      "+----------------------------------------------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|mean(features)              |\n",
      "+----------------------------+\n",
      "|[1.3333333333333333,2.0,1.0]|\n",
      "+----------------------------+\n",
      "\n",
      "+--------------+\n",
      "|mean(features)|\n",
      "+--------------+\n",
      "|[2.5,2.0,1.0] |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "df = sc.parallelize([Row(weight=1.0, features=Vectors.dense(1.0, 2.0, 1.0)),\n",
    "                     Row(weight=0.5, features=Vectors.dense(2.0, 2.0, 1.0)),\n",
    "                     Row(weight=0.0, features=Vectors.dense(3.0, 2.0, 1.0)),\n",
    "                     Row(weight=0.0, features=Vectors.dense(4.0, 2.0, 1.0))]).toDF()\n",
    "\n",
    "# create summarizer for multiple metrics \"mean\" and \"count\"\n",
    "summarizer = Summarizer.metrics(\"mean\", \"count\", \"min\", \"max\", \"normL1\")\n",
    "\n",
    "# compute statistics for multiple metrics with weight\n",
    "df.select(summarizer.summary(df.features, df.weight)).show(truncate=False)\n",
    "\n",
    "# compute statistics for multiple metrics without weight\n",
    "df.select(summarizer.summary(df.features)).show(truncate=False)\n",
    "\n",
    "# compute statistics for single metric \"mean\" with weight\n",
    "df.select(Summarizer.mean(df.features, df.weight)).show(truncate=False)\n",
    "\n",
    "# compute statistics for single metric \"mean\" without weight\n",
    "df.select(Summarizer.mean(df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- pyspark.ml.feature module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Expansion\n",
    "- Polynomial expansion is the process of expanding your features into a polynomial space, which is formulated by an n-degree combination of original dimensions. \n",
    "- The example below shows how to expand your features into a 3-degree polynomial space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------+\n",
      "|features  |polyFeatures                              |\n",
      "+----------+------------------------------------------+\n",
      "|[2.0,1.0] |[2.0,4.0,8.0,1.0,2.0,4.0,1.0,2.0,1.0]     |\n",
      "|[0.0,0.0] |[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]     |\n",
      "|[3.0,-1.0]|[3.0,9.0,27.0,-1.0,-3.0,-9.0,1.0,3.0,-1.0]|\n",
      "+----------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (Vectors.dense([2.0, 1.0]),),\n",
    "    (Vectors.dense([0.0, 0.0]),),\n",
    "    (Vectors.dense([3.0, -1.0]),)\n",
    "], [\"features\"])\n",
    "\n",
    "polyExpansion = PolynomialExpansion(degree=3, inputCol=\"features\", outputCol=\"polyFeatures\")\n",
    "polyDF = polyExpansion.transform(df)\n",
    "\n",
    "polyDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "degree=2\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "x + x^{2} + y + xy + y^{2}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "degree=3\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "x + x^{2} + x^{3} + y + xy + x^{2}y + y^{2} + xy^{2} + y^{3}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis\n",
    "pyspark.ml.feature.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[-0.44859172, -0.28423808,  0.08344545],\n",
      "             [ 0.13301986, -0.05621156,  0.04423979],\n",
      "             [-0.12523156,  0.76362648, -0.57807123],\n",
      "             [ 0.21650757, -0.56529588, -0.79554051],\n",
      "             [-0.84765129, -0.11560341, -0.15501179]])\n",
      "+--------------------+--------------------+\n",
      "|            features|         pcaFeatures|\n",
      "+--------------------+--------------------+\n",
      "| (5,[1,3],[1.0,7.0])|[1.64857282308838...|\n",
      "|[2.0,0.0,3.0,4.0,...|[-4.6451043317815...|\n",
      "|[4.0,0.0,0.0,6.0,...|[-6.4288805356764...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+-----------------------------------------------------------+\n",
      "|pcaFeatures                                                |\n",
      "+-----------------------------------------------------------+\n",
      "|[1.6485728230883807,-4.013282700516296,-5.524543751369388] |\n",
      "|[-4.645104331781534,-1.1167972663619026,-5.524543751369387]|\n",
      "|[-6.428880535676489,-5.337951427775355,-5.524543751369389] |\n",
      "+-----------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data = [(Vectors.sparse(5, [(1, 1.0), (3, 7.0)]),),\n",
    "        (Vectors.dense([2.0, 0.0, 3.0, 4.0, 5.0]),),\n",
    "        (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),)]\n",
    "df = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(df)\n",
    "\n",
    "print \"a principal components Matrix. Each column is one principal component.\", model.pc\n",
    "\n",
    "model.transform(df).show()\n",
    "result = model.transform(df).select(\"pcaFeatures\")\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators (Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "pyspark.ml.regression module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_linear_regression_data.txt\")\n",
    "training.printSchema()\n",
    "print \"First row:\\n{}\\n\".format(training.first())\n",
    "\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print \"Coefficients:\\n{}\\n\".format(lrModel.coefficients)\n",
    "print \"Intercept:\\n{}\\n\".format(lrModel.intercept)\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print \"numIterations:\\n{}\\n\".format(trainingSummary.totalIterations)\n",
    "print \"objectiveHistory:\\n{}\\n\".format(trainingSummary.objectiveHistory)\n",
    "trainingSummary.residuals.show()\n",
    "print \"RMSE:\\n{}\\n\".format(trainingSummary.rootMeanSquaredError)\n",
    "print \"r2:\\n{}\\n\".format(trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalized Linear Regression\n",
    "\n",
    "Fit a Generalized Linear Model specified by giving a symbolic description of the linear predictor (link function) and a description of the error distribution (family). It supports “gaussian”, “binomial”, “poisson”, “gamma” and “tweedie” as family. Valid link functions for each family is listed below. The first link function of each family is the default one.\n",
    "- “gaussian” -> “identity”, “log”, “inverse”\n",
    "- “binomial” -> “logit”, “probit”, “cloglog”\n",
    "- “poisson” -> “log”, “identity”, “sqrt”\n",
    "- “gamma” -> “inverse”, “identity”, “log”\n",
    "- “tweedie” -> power link function specified through “linkPower”. The default link power in the tweedie family is 1 - variancePower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Load training data\n",
    "dataset = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_linear_regression_data.txt\")\n",
    "\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(dataset)\n",
    "\n",
    "# Print the coefficients and intercept for generalized linear regression model\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(summary.tValues))\n",
    "print(\"P Values: \" + str(summary.pValues))\n",
    "print(\"Dispersion: \" + str(summary.dispersion))\n",
    "print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "print(\"Deviance: \" + str(summary.deviance))\n",
    "print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "print(\"AIC: \" + str(summary.aic))\n",
    "print(\"Deviance Residuals: \")\n",
    "summary.residuals().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "pyspark.ml.classification module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binomial logistic regression\n",
    "- coefficients and intercept methods on a logistic regression model trained with multinomial family are not supported. Use coefficientMatrix and interceptVector instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "training.show()\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "print \"accuracy:\", trainingSummary.accuracy\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "print \"ROC:\"\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "print \"fMeasureByLabel:\", trainingSummary.fMeasureByLabel()\n",
    "\n",
    "print \"fMeasureByThreshold:\"\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "fMeasure.show()\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)\n",
    "\n",
    "print \"falsePositiveRateByLabel:\", trainingSummary.falsePositiveRateByLabel\n",
    "\n",
    "print \"labels:\", trainingSummary.labels\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "print(\"precision-recall curve:\")\n",
    "trainingSummary.pr.show()\n",
    "\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial logistic regression\n",
    "- This is supported via multinomial logistic (`softmax`) regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark \\\n",
    "    .read \\\n",
    "    .format(\"libsvm\") \\\n",
    "    .load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Machine Classifier\n",
    "- This binary classifier optimizes the Hinge Loss using the OWLQN optimizer.\n",
    "- Only supports L2 regularization currently.\n",
    "- Support only binary classification with linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(training)\n",
    "\n",
    "print lsvcModel.numFeatures\n",
    "print lsvcModel.numClasses\n",
    "\n",
    "# Print the coefficients and intercept for linear SVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier\n",
    "- It supports both binary and multiclass labels, as well as both continuous and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "dt_model = model.stages[2]\n",
    "print dt_model.numNodes\n",
    "print dt_model.depth\n",
    "print dt_model.featureImportances\n",
    "print dt_model.numFeatures\n",
    "print dt_model.numClasses\n",
    "print dt_model.toDebugString\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(20)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier\n",
    "- It supports both binary and multiclass labels, as well as both continuous and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient-Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "pyspark.ml.clustering module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means\n",
    "- The MLlib implementation includes a parallelized variant of the [k-means++](http://en.wikipedia.org/wiki/K-means%2B%2B) method called [kmeans||](http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf) (pronounced. as. KMeans. Parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(dataset)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(dataset)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bisecting K-means\n",
    "- Bisecting k-means is a kind of hierarchical clustering using a divisive (or “top-down”) approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n",
    "- Bisecting K-means can often be much faster than regular K-means, but it will generally produce a different clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "# Trains a bisecting k-means model.\n",
    "bkm = BisectingKMeans().setK(2).setSeed(1)\n",
    "model = bkm.fit(dataset)\n",
    "\n",
    "# Evaluate clustering.\n",
    "cost = model.computeCost(dataset)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(cost))\n",
    "\n",
    "# Shows the result.\n",
    "print(\"Cluster Centers: \")\n",
    "centers = model.clusterCenters()\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Mixture Model (GMM)\n",
    "- This implementation uses the expectation-maximization algorithm to induce the maximum-likelihood model given a set of samples.\n",
    "- For high-dimensional data (with many features), this algorithm may perform poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "# loads data\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "gmm = GaussianMixture().setK(2).setSeed(538009335)\n",
    "model = gmm.fit(dataset)\n",
    "\n",
    "print(\"Gaussians shown as a DataFrame: \")\n",
    "model.gaussiansDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (잠재 디리클레 할당)\n",
    "- a topic modeling angorithm for text documents.\n",
    "- Terminology:\n",
    "  - “term” = “word”: an element of the vocabulary\n",
    "  - “token”: instance of a term appearing in a document\n",
    "  - “topic”: multinomial distribution over terms representing some concept\n",
    "  - “document”: one piece of text, corresponding to one row in the input data\n",
    "- Original LDA paper (journal version): Blei, Ng, and Jordan. “Latent Dirichlet Allocation.” JMLR, 2003.\n",
    "- Input data (featuresCol): LDA is given a collection of documents as input data, via the featuresCol parameter. Each document is specified as a Vector of length vocabSize, where each entry is the count for the corresponding term (word) in the document. Feature transformers such as pyspark.ml.feature.Tokenizer and pyspark.ml.feature.CountVectorizer can be useful for converting text to word count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_lda_libsvm_data.txt\")\n",
    "\n",
    "# Trains a LDA model.\n",
    "lda = LDA(k=10, maxIter=10)\n",
    "model = lda.fit(dataset)\n",
    "\n",
    "ll = model.logLikelihood(dataset)\n",
    "lp = model.logPerplexity(dataset)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n",
    "\n",
    "# Describe topics.\n",
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)\n",
    "\n",
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutivariate Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation\n",
    "pyspark.ml.recommendation module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "lines = spark.read.text(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/als/sample_movielens_ratings.txt\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "                                     rating=float(p[2]), timestamp=long(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "#als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", implicitPrefs=True)\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.show(5, truncate=False)\n",
    "\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "movieRecs.show(5, truncate=False)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "users.show()\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "userSubsetRecs.show(5, truncate=False)\n",
    "\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movies.show()\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "userSubsetRecs.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent Pattern Mining\n",
    "pyspark.ml.fpm module\n",
    "\n",
    "- A parallel FP-growth algorithm to mine frequent itemsets.\n",
    "- The algorithm is described in Li et al., PFP: Parallel FP-Growth for Query Recommendation [LI2008](http://dx.doi.org/10.1145/1454008.1454027).\n",
    "- PFP distributes computation in such a way that each worker executes an independent group of mining tasks.\n",
    "- The FP-Growth algorithm is described in Han et al., Mining frequent patterns without candidate generation [HAN2000](http://dx.doi.org/10.1145/335191.335372)\n",
    "\n",
    "- Mining frequent items, itemsets, subsequences, or other substructures is usually among the first steps to analyze a large-scale dataset, which has been an active research topic in data mining for years. We refer users to Wikipedia’s association rule learning for more information.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (0, [1, 2, 5]),\n",
    "    (1, [1, 2, 3, 5]),\n",
    "    (2, [1, 2])\n",
    "], [\"id\", \"items\"])\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fpGrowth.fit(df)\n",
    "\n",
    "# Display frequent itemsets.\n",
    "model.freqItemsets.show()\n",
    "\n",
    "# Display generated association rules.\n",
    "model.associationRules.show()\n",
    "\n",
    "# transform examines the input items against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "- pyspark.ml.evaluation module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "pyspark.ml.tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "pyspark.ml.tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "pyspark.ml.Pipeline and pyspark.ml.PipelineModel\n",
    "\n",
    "\n",
    "- `Transformer` : Abstract class for transformers that `transform one dataset into another`.\n",
    "\n",
    "- `UnaryTransformer` : Abstract class for transformers that `take one input column, apply transformation, and output the result as a new column`.\n",
    "\n",
    "- `Estimator` : Abstract class for estimators that `fit models to data`.\n",
    "\n",
    "- `Model` : Abstract class for `models that are fitted by estimators`.\n",
    "\n",
    "- `Pipeline` : A simple pipeline, which `acts as an estimator`. A Pipeline consists of a sequence of stages, each of which is either an Estimator or a Transformer. When Pipeline.fit() is called, the stages are executed in order. The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages. If stages is an empty list, the pipeline acts as an identity transformer.\n",
    "  - If a stage is an `Estimator`, its `Estimator.fit()` method will be called on the input dataset to fit a model. Then the model, which is a transformer, will be used to transform the dataset as the input to the next stage. \n",
    "  - If a stage is a `Transformer`, its `Transformer.transform()` method will be called to produce the dataset for the next stage. \n",
    "\n",
    "- `PipelineModel` : Represents `a compiled pipeline with transformers and fitted models`.\n",
    "\n",
    "- `DAG Pipelines`: A Pipeline’s stages are specified as an ordered array. The examples given here are all for linear Pipelines, i.e., Pipelines in which each stage uses data produced by the previous stage. It is possible to create non-linear Pipelines as long as the data flow graph forms a Directed Acyclic Graph (DAG). This graph is currently specified implicitly based on the input and output column names of each stage (generally specified as parameters). If the Pipeline forms a DAG, then the stages must be specified in topological order.\n",
    "\n",
    "- `Runtime checking`: Since Pipelines can operate on DataFrames with varied types, they cannot use compile-time type checking. Pipelines and PipelineModels instead do runtime checking before actually running the Pipeline. This type checking is done using the DataFrame schema, a description of the data types of columns in the DataFrame.\n",
    "\n",
    "- `Unique Pipeline stages`: A Pipeline’s stages should be unique instances. E.g., the same instance myHashingTF should not be inserted into the Pipeline twice since Pipeline stages must have unique IDs. However, different instances myHashingTF1 and myHashingTF2 (both of type HashingTF) can be put into the same Pipeline since different instances will be created with different IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n",
    "\n",
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(training)\n",
    "\n",
    "# Prepare test documents, which are unlabeled (id, text) tuples.\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"spark hadoop spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents and print columns of interest.\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    rid, text, prob, prediction = row\n",
    "    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://spark.apache.org/docs/latest/ml-guide.html\n",
    "- https://www.wikipedia.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
