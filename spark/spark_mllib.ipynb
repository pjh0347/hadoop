{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Machine Learning Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- Linear Algebra\n",
    "  - Vector\n",
    "  - Matrix\n",
    "- Statistics\n",
    "  - Correlation\n",
    "  - Hypothesis Testing\n",
    "  - Summarizer\n",
    "- Feature Engineering\n",
    "  - Polynomial Expansion\n",
    "  - Dimensionality Reduction\n",
    "    - Principal Component Analysis\n",
    "- Estimators\n",
    "  - Regression\n",
    "    - Linear Regression\n",
    "    - Generalized Linear Regression\n",
    "    - ~~Accelerated Failure Time (AFT) Model Survival Regression~~\n",
    "    - ~~Decision Tree Regressor~~\n",
    "    - ~~Gradient-Boosted Tree Regressor~~\n",
    "    - ~~Isotonic Regression~~\n",
    "    - ~~Random Forest Regressor~~\n",
    "  - Classification\n",
    "    - Logistic Regression\n",
    "    - Linear Support Vector Machine Classifier\n",
    "    - Decision Tree Classifier\n",
    "    - Random Forest Classifier\n",
    "    - ~~Gradient-Boosted Tree Classifier~~\n",
    "    - ~~Naive Bayes Classifier~~\n",
    "    - ~~Multilayer Perceptron Classifier~~\n",
    "    - ~~OneVsRest Classifier~~\n",
    "  - Clustering\n",
    "    - K-means\n",
    "    - Bisecting K-means\n",
    "    - Gaussian Mixture Model\n",
    "    - Latent Dirichlet Allocation\n",
    "    - ~~Power Iteration Clustering~~\n",
    "  - Recommendation\n",
    "    - Alternating Least Squares\n",
    "    - Frequent Pattern Mining\n",
    "- Evaluators\n",
    "  - RegressionEvaluator\n",
    "  - BinaryClassificationEvaluator\n",
    "  - MulticlassClassificationEvaluator\n",
    "  - ClusteringEvaluator\n",
    "- Model Selection\n",
    "- Cross Validation\n",
    "- Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[4]\") \\\n",
    "                    .appName(\"spark MLlib tutorial\") \\\n",
    "                    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "- pyspark.ml.linalg module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dense & sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0,2.0]\n",
      "[4.0,6.0]\n",
      "[3.0,8.0]\n",
      "[3.0,2.0]\n",
      "[-1.0,0.0]\n",
      "[0.5,1.0]\n",
      "[1.0,0.0]\n",
      "[-1.0,-2.0]\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "v = Vectors.dense([1.0, 2.0])\n",
    "u = Vectors.sparse(2, [(0, 3.0), (1, 4.0)])\n",
    "\n",
    "print u - v\n",
    "print u + v\n",
    "print v * u\n",
    "print u / v\n",
    "print v - 2\n",
    "print v / 2\n",
    "print v % 2\n",
    "print -v\n",
    "\n",
    "print type(v.toArray())\n",
    "print type(v.values)\n",
    "\n",
    "# TypeError: unsupported operand type(s) for /: 'SparseVector' and 'int'\n",
    "#print u / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dot product\n",
    "- Compute the dot product of two Vectors.\n",
    "- Equivalent to calling `numpy.dot` of the two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense.dot(SparseVector(2, [0, 1], [2., 1.])) :  4.0\n",
      "dense.dot(range(1, 3)) :  5.0\n",
      "dense.dot(np.array(range(1, 3))) :  5.0\n",
      "dense.dot(np.reshape([1., 2., 3., 4.], (2, 2))) :  [ 7. 10.]\n",
      "sparse.indices :  [1 3]\n",
      "sparse.size :  4\n",
      "sparse2.indices :  [2]\n",
      "sparse2.size :  4\n",
      "25.0\n",
      "22.0\n",
      "0.0\n",
      "[22. 22.]\n"
     ]
    }
   ],
   "source": [
    "dense = DenseVector([1.0, 2.0])\n",
    "print \"dense.dot(SparseVector(2, [0, 1], [2., 1.])) : \", dense.dot(SparseVector(2, [0, 1], [2., 1.]))\n",
    "print \"dense.dot(range(1, 3)) : \", dense.dot(range(1, 3))\n",
    "print \"dense.dot(np.array(range(1, 3))) : \", dense.dot(np.array(range(1, 3)))\n",
    "print \"dense.dot(np.reshape([1., 2., 3., 4.], (2, 2))) : \", dense.dot(np.reshape([1., 2., 3., 4.], (2, 2)))\n",
    "#print dense.dot([1.,]) # dimension mismatch\n",
    "#print dense.dot(np.reshape([1., 2., 3.], (3, 1), order='F')) # dimension mismatch\n",
    "\n",
    "sparse = SparseVector(4, [1, 3], [3.0, 4.0])\n",
    "sparse2 = SparseVector(4, [2], [1.0])\n",
    "print \"sparse.indices : \", sparse.indices\n",
    "print \"sparse.size : \", sparse.size\n",
    "print \"sparse2.indices : \", sparse2.indices\n",
    "print \"sparse2.size : \", sparse2.size\n",
    "print sparse.dot(sparse)\n",
    "print sparse.dot([1.0, 2.0, 3.0, 4.0])\n",
    "print sparse.dot(sparse2)\n",
    "print sparse.dot(np.array([[1, 1], [2, 2], [3, 3], [4, 4]]))\n",
    "#print a.dot([1., 2., 3.]) # dimension mismatch\n",
    "#print a.dot(np.array([1., 2.])) # dimension mismatch\n",
    "#print a.dot(DenseVector([1., 2.])) # dimension mismatch\n",
    "#print a.dot(np.zeros((3, 2))) # dimension mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = DenseVector([1.0, 2.0])\n",
    "sparse = SparseVector(2, [0, 1], [1.0, 2.0])\n",
    "assert(dense.values.tolist()==sparse.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### norm\n",
    "- L1, L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7416573867739413\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "v = DenseVector([0, -1, 2, -3])\n",
    "print v.norm(2)\n",
    "print v.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4031242374328485\n",
      "6.40312423743\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "v = DenseVector([4, 5])\n",
    "print v.norm(2)\n",
    "print math.sqrt(4**2 + 5**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "v = DenseVector([4, 5])\n",
    "print v.norm(1)\n",
    "print abs(4 + 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squared distance\n",
    "- Squared Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dense1 = DenseVector([1., 2.])\n",
    "dense2 = np.array([2., 1.])\n",
    "dense3 = [2., 1.]\n",
    "sparse1 = SparseVector(2, [0, 1], [2., 1.])\n",
    "\n",
    "print dense1.squared_distance(dense1)\n",
    "print dense1.squared_distance(dense2)\n",
    "print dense1.squared_distance(dense3)\n",
    "print dense1.squared_distance(sparse1)\n",
    "#dense1.squared_distance([1.,]) # dimension mismatch\n",
    "#dense1.squared_distance(SparseVector(1, [0,], [1.,])) # dimension mismatch\n",
    "\n",
    "print (1-2)**2 + (2-1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[0., 3., 6.],\n",
      "             [1., 4., 7.],\n",
      "             [2., 5., 8.]])\n",
      "DenseMatrix([[0., 1., 2.],\n",
      "             [3., 4., 5.],\n",
      "             [6., 7., 8.]])\n",
      "DenseMatrix([[0., 3., 6.],\n",
      "             [1., 4., 7.],\n",
      "             [2., 5., 8.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Matrices\n",
    "from pyspark.ml.linalg import SparseMatrix\n",
    "from pyspark.ml.linalg import DenseMatrix\n",
    "\n",
    "dense = DenseMatrix(3, 3, range(9))\n",
    "print dense\n",
    "\n",
    "dense2 = DenseMatrix(3, 3, range(9), isTransposed=True)\n",
    "print dense2\n",
    "\n",
    "dense3 = Matrices.dense(3, 3, range(9))\n",
    "print dense3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "- pyspark.ml.stat module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "%matplotlib inline\n",
    "\n",
    "data = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n",
    "        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n",
    "        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n",
    "        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "def plot_heatmap(pandas_df):\n",
    "    ndarray = pandas_df.to_numpy()\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    #plt.title('Pearson correlation matrix')\n",
    "    heatmap = plt.pcolor(ndarray)\n",
    "    y_len, x_len = ndarray.shape\n",
    "    for y in range(y_len):\n",
    "        for x in range(x_len):\n",
    "            plt.text(x + 0.5, y + 0.5, '%.4f' % ndarray[y, x],\n",
    "                     horizontalalignment='center',\n",
    "                     verticalalignment='center')\n",
    "    plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pearson\n",
    "- Requirements for Pearson's correlation coefficient\n",
    "  - Scale of measurement should be interval or ratio\n",
    "  - Variables should be approximately normally distributed\n",
    "  - The association should be linear\n",
    "  - There should be no outliers in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "population\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\rho _{X,Y}={\\frac {\\operatorname {cov} (X,Y)}{\\sigma _{X}\\sigma _{Y}}}}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "{\\displaystyle r_{xy}={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{{\\sqrt {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}{\\sqrt {\\sum _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}}}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pearson(features): matrix (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400471</td>\n",
       "      <td>0.913596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2         3\n",
       "0  1.000000  0.055641  NaN  0.400471\n",
       "1  0.055641  1.000000  NaN  0.913596\n",
       "2       NaN       NaN  1.0       NaN\n",
       "3  0.400471  0.913596  NaN  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = Correlation.corr(df, \"features\", method=\"pearson\")\n",
    "\n",
    "result.printSchema()\n",
    "\n",
    "result_array = result.head()['pearson(features)'].toArray()\n",
    "pandas_df = pd.DataFrame(result_array)\n",
    "display(pandas_df)\n",
    "\n",
    "plot_heatmap(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spearman(features): matrix (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2         3\n",
       "0  1.000000  0.105409  NaN  0.400000\n",
       "1  0.105409  1.000000  NaN  0.948683\n",
       "2       NaN       NaN  1.0       NaN\n",
       "3  0.400000  0.948683  NaN  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = Correlation.corr(df, \"features\", method=\"spearman\")\n",
    "\n",
    "result.printSchema()\n",
    "\n",
    "result_array = result.head()['spearman(features)'].toArray()\n",
    "pandas_df = pd.DataFrame(result_array)\n",
    "display(pandas_df)\n",
    "\n",
    "plot_heatmap(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson’s Chi-squared Test\n",
    "- Independence test for every feature against the label.\n",
    "- degreesOfFreedom : the number of values in the final calculation of a statistic that are free to vary. It is equal to the number of levels (k) of the categorical variable minus 1. (k-1)\n",
    "- statistics : 검정 통계량은 표본 데이터에서 계산되어 가설 검정에 사용되는 랜덤 변수입니다. 검정 통계량을 사용하여 귀무 가설의 기각 여부를 확인할 수 있습니다. 검정 통계량은 데이터를 귀무 가설 하에서 기대되는 값과 비교합니다. 검정 통계량은 p-값을 계산하기 위해 사용됩니다. 가설 검정마다 귀무 가설에서 가정된 확률 모형을 기반으로 각기 다른 검정 통계량을 사용합니다.\n",
    "  - 카이-제곱 검정 통계량\n",
    "\n",
    "    $\n",
    "\\begin{equation}\n",
    "{\\displaystyle E_{i} = n {\\sum _{i=1}^{k}{p_{i}}} }\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "    $\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\chi ^{2} = {\\sum _{i=1}^{k}{\\frac {(O_{i}-E_{i})^{2}} {E_{i}} }}}\n",
    "\\end{equation}\n",
    "$\n",
    "    - n : 샘플 수\n",
    "    - k : 구별 범주의 수\n",
    "    - p$_{i}$ : i번째 범주에 대한 검정 비율\n",
    "    - O$_{i}$ : i번째 범주에 대한 관측값\n",
    "    - E$_{i}$ : i번째 범주에 대한 기대값  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example\n",
    "\n",
    "| _            | A   | B   | C   | D   | Total |\n",
    "|--------------|-----|-----|-----|-----|-------|\n",
    "| White collar | 90  | 60  | 104 | 95  | 349   |\n",
    "| Blue collar  | 30  | 50  | 51  | 20  | 151   |\n",
    "| No collar    | 30  | 40  | 45  | 35  | 150   |\n",
    "| Total        | 150 | 150 | 200 | 150 | 650   |\n",
    "\n",
    "- $150\\times\\frac{349}{650} \\approx 80.54$\n",
    "\n",
    "- $\\frac{\\left(\\text{observed}-\\text{expected}\\right)^2}{\\text{expected}} = \\frac{\\left(90-80.54\\right)^2}{80.54} \\approx 1.11$\n",
    "\n",
    "- 판단\n",
    "  - 방법1) DF 과 significance level을 이용하여 Chi-square Distribution Table 에서 상한 지점을 찾아 $\\chi ^{2}$ statistic 과 비교.\n",
    "  - 방법2) DF 과 $ \\chi ^{2} $ statistic 을 이용하여 계산을 통해 pvalue 를 구하여 significance level 과 비교."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pValues: vector (nullable = true)\n",
      " |-- degreesOfFreedom: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = false)\n",
      " |-- statistics: vector (nullable = true)\n",
      "\n",
      "+--------------------------------------------+----------------+-------------+\n",
      "|pValues                                     |degreesOfFreedom|statistics   |\n",
      "+--------------------------------------------+----------------+-------------+\n",
      "|[0.3062189184132784,0.01430587843542952,1.0]|[5, 1, 0]       |[6.0,6.0,0.0]|\n",
      "+--------------------------------------------+----------------+-------------+\n",
      "\n",
      "Independence (fail to reject null hypotheses)\n",
      "Not independence (reject null hypotheses)\n",
      "Independence (fail to reject null hypotheses)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "data = [[0, Vectors.dense([0, 10, 1])],\n",
    "        [0, Vectors.dense([1, 10, 1])],\n",
    "        [0, Vectors.dense([2, 10, 1])],\n",
    "        [1, Vectors.dense([3, 11, 1])],\n",
    "        [1, Vectors.dense([4, 11, 1])],\n",
    "        [1, Vectors.dense([5, 11, 1])]]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"label\", \"features\"])\n",
    "\n",
    "result = ChiSquareTest.test(df, \"features\", \"label\")\n",
    "\n",
    "result.printSchema()\n",
    "result.show(truncate=False)\n",
    "\n",
    "null_hypotheses = 'Independence'\n",
    "alternative_hypotheses = 'Not independence'\n",
    "significance_level = 0.05\n",
    "pValues = result.head().pValues\n",
    "\n",
    "for pValue in pValues:\n",
    "    if pValue <= significance_level:\n",
    "        print \"{} (reject null hypotheses)\".format(alternative_hypotheses)\n",
    "    else:\n",
    "        print \"{} (fail to reject null hypotheses)\".format(null_hypotheses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a statistic value of the first column of the features\n",
    "\n",
    "| _     | 0 | 1 | 2 | 3 | 4 | 5 | Total |\n",
    "|-------|---|---|---|---|---|---|-------|\n",
    "| 0     | 1 | 1 | 1 | 0 | 0 | 0 | 3     |\n",
    "| 1     | 0 | 0 | 0 | 1 | 1 | 1 | 3     |\n",
    "| Total | 1 | 1 | 1 | 1 | 1 | 1 | 6     |\n",
    "\n",
    "모든 셀의 기댓값은 $1\\times\\frac{3}{6} = 0.5$\n",
    "\n",
    "$\\frac{\\left(1-0.5\\right)^2}{0.5} = 0.5$ => 6개\n",
    "\n",
    "$\\frac{\\left(0-0.5\\right)^2}{0.5} = 0.5$ => 6개\n",
    "\n",
    "총 합은 : 0.5 * 12 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kolmogorov Smirnov (콜모고로프-스미르노프) Test\n",
    "- Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pValue: double (nullable = false)\n",
      " |-- statistic: double (nullable = false)\n",
      "\n",
      "+------------------+--------------------+\n",
      "|pValue            |statistic           |\n",
      "+------------------+--------------------+\n",
      "|0.7297807285638009|0.021617989891593914|\n",
      "+------------------+--------------------+\n",
      "\n",
      "The sample data comes from normal distribution (fail to reject null hypotheses)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.stat import KolmogorovSmirnovTest\n",
    "\n",
    "mean = 0.0\n",
    "stdev = 1.0\n",
    "variance = stdev**2\n",
    "size = 1000\n",
    "sample = np.random.normal(mean, stdev, size)\n",
    "pandas_df = pd.DataFrame(sample, columns=['sample'])\n",
    "data = spark.createDataFrame(pandas_df, ['sample'])\n",
    "\n",
    "result = KolmogorovSmirnovTest.test(data, 'sample', 'norm', mean, variance)\n",
    "\n",
    "result.printSchema()\n",
    "result.show(truncate=False)\n",
    "\n",
    "null_hypotheses = 'The sample data comes from normal distribution'\n",
    "alternative_hypotheses = 'The sample data does not comes from normal distribution'\n",
    "significance_level = 0.05\n",
    "pValue = result.head().pValue\n",
    "if pValue <= significance_level:\n",
    "    print \"{} (reject null hypotheses)\".format(alternative_hypotheses)\n",
    "else:\n",
    "    print \"{} (fail to reject null hypotheses)\".format(null_hypotheses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean: a vector that contains the coefficient-wise mean.\n",
    "- variance: a vector that contains the coefficient-wise variance.\n",
    "- count: the count of all vectors seen.\n",
    "- numNonzeros: a vector with the number of non-zeros for each coefficients\n",
    "- max: the maximum for each coefficient.\n",
    "- min: the minimum for each coefficient.\n",
    "- normL2: the Euclidean norm for each coefficient.\n",
    "- normL1: the L1 norm of each coefficient (sum of the absolute values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+\n",
      "|aggregate_metrics(features, weight)                                           |\n",
      "+------------------------------------------------------------------------------+\n",
      "|[[1.3333333333333333,2.0,1.0], 2, [1.0,2.0,1.0], [2.0,2.0,1.0], [2.0,3.0,1.5]]|\n",
      "+------------------------------------------------------------------------------+\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|aggregate_metrics(features, 1.0)                                |\n",
      "+----------------------------------------------------------------+\n",
      "|[[2.5,2.0,1.0], 4, [1.0,2.0,1.0], [4.0,2.0,1.0], [10.0,8.0,4.0]]|\n",
      "+----------------------------------------------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|mean(features)              |\n",
      "+----------------------------+\n",
      "|[1.3333333333333333,2.0,1.0]|\n",
      "+----------------------------+\n",
      "\n",
      "+--------------+\n",
      "|mean(features)|\n",
      "+--------------+\n",
      "|[2.5,2.0,1.0] |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "df = sc.parallelize([Row(weight=1.0, features=Vectors.dense(1.0, 2.0, 1.0)),\n",
    "                     Row(weight=0.5, features=Vectors.dense(2.0, 2.0, 1.0)),\n",
    "                     Row(weight=0.0, features=Vectors.dense(3.0, 2.0, 1.0)),\n",
    "                     Row(weight=0.0, features=Vectors.dense(4.0, 2.0, 1.0))]).toDF()\n",
    "\n",
    "# create summarizer for multiple metrics \"mean\" and \"count\"\n",
    "summarizer = Summarizer.metrics(\"mean\", \"count\", \"min\", \"max\", \"normL1\")\n",
    "\n",
    "# compute statistics for multiple metrics with weight\n",
    "df.select(summarizer.summary(df.features, df.weight)).show(truncate=False)\n",
    "\n",
    "# compute statistics for multiple metrics without weight\n",
    "df.select(summarizer.summary(df.features)).show(truncate=False)\n",
    "\n",
    "# compute statistics for single metric \"mean\" with weight\n",
    "df.select(Summarizer.mean(df.features, df.weight)).show(truncate=False)\n",
    "\n",
    "# compute statistics for single metric \"mean\" without weight\n",
    "df.select(Summarizer.mean(df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- pyspark.ml.feature module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Expansion\n",
    "- Polynomial expansion is the process of expanding your features into a polynomial space, which is formulated by an n-degree combination of original dimensions. \n",
    "- The example below shows how to expand your features into a 3-degree polynomial space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------+\n",
      "|features  |polyFeatures                              |\n",
      "+----------+------------------------------------------+\n",
      "|[2.0,1.0] |[2.0,4.0,8.0,1.0,2.0,4.0,1.0,2.0,1.0]     |\n",
      "|[0.0,0.0] |[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]     |\n",
      "|[3.0,-1.0]|[3.0,9.0,27.0,-1.0,-3.0,-9.0,1.0,3.0,-1.0]|\n",
      "+----------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (Vectors.dense([2.0, 1.0]),),\n",
    "    (Vectors.dense([0.0, 0.0]),),\n",
    "    (Vectors.dense([3.0, -1.0]),)\n",
    "], [\"features\"])\n",
    "\n",
    "polyExpansion = PolynomialExpansion(degree=3, inputCol=\"features\", outputCol=\"polyFeatures\")\n",
    "polyDF = polyExpansion.transform(df)\n",
    "\n",
    "polyDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "degree=2\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "x + x^{2} + y + xy + y^{2}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "degree=3\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "x + x^{2} + x^{3} + y + xy + x^{2}y + y^{2} + xy^{2} + y^{3}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis\n",
    "pyspark.ml.feature.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.0, 0.0, 7.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.0, 0.0, 3.0, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4.0, 0.0, 0.0, 6.0, 7.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    features\n",
       "0  (0.0, 1.0, 0.0, 7.0, 0.0)\n",
       "1  [2.0, 0.0, 3.0, 4.0, 5.0]\n",
       "2  [4.0, 0.0, 0.0, 6.0, 7.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a principal components Matrix :\n",
      "DenseMatrix([[-0.44859172, -0.28423808,  0.08344545],\n",
      "             [ 0.13301986, -0.05621156,  0.04423979],\n",
      "             [-0.12523156,  0.76362648, -0.57807123],\n",
      "             [ 0.21650757, -0.56529588, -0.79554051],\n",
      "             [-0.84765129, -0.11560341, -0.15501179]])\n",
      "\n",
      "model.transform(df)\n",
      "+---------------------+-----------------------------------------------------------+\n",
      "|features             |pcaFeatures                                                |\n",
      "+---------------------+-----------------------------------------------------------+\n",
      "|(5,[1,3],[1.0,7.0])  |[1.6485728230883807,-4.013282700516296,-5.524543751369388] |\n",
      "|[2.0,0.0,3.0,4.0,5.0]|[-4.645104331781534,-1.1167972663619026,-5.524543751369387]|\n",
      "|[4.0,0.0,0.0,6.0,7.0]|[-6.428880535676489,-5.337951427775355,-5.524543751369389] |\n",
      "+---------------------+-----------------------------------------------------------+\n",
      "\n",
      "\n",
      "model.transform(df).select('pcaFeatures')\n",
      "+-----------------------------------------------------------+\n",
      "|pcaFeatures                                                |\n",
      "+-----------------------------------------------------------+\n",
      "|[1.6485728230883807,-4.013282700516296,-5.524543751369388] |\n",
      "|[-4.645104331781534,-1.1167972663619026,-5.524543751369387]|\n",
      "|[-6.428880535676489,-5.337951427775355,-5.524543751369389] |\n",
      "+-----------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data = [(Vectors.sparse(5, [(1, 1.0), (3, 7.0)]),),\n",
    "        (Vectors.dense([2.0, 0.0, 3.0, 4.0, 5.0]),),\n",
    "        (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),)]\n",
    "df = spark.createDataFrame(data, [\"features\"])\n",
    "print \"data : \"\n",
    "display(df.toPandas())\n",
    "print\n",
    "\n",
    "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(df)\n",
    "\n",
    "print \"a principal components Matrix :\" # Each column is one principal component.\n",
    "print model.pc\n",
    "print\n",
    "\n",
    "print \"model.transform(df)\"\n",
    "model.transform(df).show(truncate=False)\n",
    "print\n",
    "\n",
    "result = model.transform(df).select(\"pcaFeatures\")\n",
    "print \"model.transform(df).select('pcaFeatures')\"\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "pyspark.ml.regression module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "- standardization : whether to standardize the training features before fitting the model.\n",
    "- solver : The solver algorithm for optimization. Supported options: auto, normal, l-bfgs.\n",
    "- regParam : regularization parameter (>= 0).\n",
    "- loss : The loss function to be optimized. Supported options: squaredError, huber.\n",
    "- epsilon : The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber.\n",
    "- tol : the convergence tolerance for iterative algorithms (>= 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema:\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature#0</th>\n",
       "      <th>feature#1</th>\n",
       "      <th>feature#2</th>\n",
       "      <th>feature#3</th>\n",
       "      <th>feature#4</th>\n",
       "      <th>feature#5</th>\n",
       "      <th>feature#6</th>\n",
       "      <th>feature#7</th>\n",
       "      <th>feature#8</th>\n",
       "      <th>feature#9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.490010</td>\n",
       "      <td>0.455127</td>\n",
       "      <td>0.366447</td>\n",
       "      <td>-0.382561</td>\n",
       "      <td>-0.445843</td>\n",
       "      <td>0.331098</td>\n",
       "      <td>0.806745</td>\n",
       "      <td>-0.262434</td>\n",
       "      <td>-0.448504</td>\n",
       "      <td>-0.072693</td>\n",
       "      <td>0.565804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257782</td>\n",
       "      <td>0.838656</td>\n",
       "      <td>-0.127018</td>\n",
       "      <td>0.499812</td>\n",
       "      <td>-0.226866</td>\n",
       "      <td>-0.645243</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>-0.580465</td>\n",
       "      <td>0.651932</td>\n",
       "      <td>-0.655564</td>\n",
       "      <td>0.174855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.438870</td>\n",
       "      <td>0.502561</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>0.160050</td>\n",
       "      <td>0.505020</td>\n",
       "      <td>-0.937164</td>\n",
       "      <td>-0.284160</td>\n",
       "      <td>0.635594</td>\n",
       "      <td>-0.164625</td>\n",
       "      <td>0.948071</td>\n",
       "      <td>0.426813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-19.782763</td>\n",
       "      <td>-0.038851</td>\n",
       "      <td>-0.416687</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>0.640984</td>\n",
       "      <td>0.273289</td>\n",
       "      <td>-0.261757</td>\n",
       "      <td>-0.279490</td>\n",
       "      <td>-0.130678</td>\n",
       "      <td>-0.085366</td>\n",
       "      <td>-0.054623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.966594</td>\n",
       "      <td>-0.061955</td>\n",
       "      <td>0.654645</td>\n",
       "      <td>-0.697937</td>\n",
       "      <td>0.667732</td>\n",
       "      <td>-0.079387</td>\n",
       "      <td>-0.438856</td>\n",
       "      <td>-0.608072</td>\n",
       "      <td>-0.641453</td>\n",
       "      <td>0.731374</td>\n",
       "      <td>-0.026819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  feature#0  feature#1  feature#2  feature#3  feature#4  \\\n",
       "0  -9.490010   0.455127   0.366447  -0.382561  -0.445843   0.331098   \n",
       "1   0.257782   0.838656  -0.127018   0.499812  -0.226866  -0.645243   \n",
       "2  -4.438870   0.502561   0.142081   0.160050   0.505020  -0.937164   \n",
       "3 -19.782763  -0.038851  -0.416687   0.899720   0.640984   0.273289   \n",
       "4  -7.966594  -0.061955   0.654645  -0.697937   0.667732  -0.079387   \n",
       "\n",
       "   feature#5  feature#6  feature#7  feature#8  feature#9  \n",
       "0   0.806745  -0.262434  -0.448504  -0.072693   0.565804  \n",
       "1   0.188700  -0.580465   0.651932  -0.655564   0.174855  \n",
       "2  -0.284160   0.635594  -0.164625   0.948071   0.426813  \n",
       "3  -0.261757  -0.279490  -0.130678  -0.085366  -0.054623  \n",
       "4  -0.438856  -0.608072  -0.641453   0.731374  -0.026819  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature#0</th>\n",
       "      <th>feature#1</th>\n",
       "      <th>feature#2</th>\n",
       "      <th>feature#3</th>\n",
       "      <th>feature#4</th>\n",
       "      <th>feature#5</th>\n",
       "      <th>feature#6</th>\n",
       "      <th>feature#7</th>\n",
       "      <th>feature#8</th>\n",
       "      <th>feature#9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.256889</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.057697</td>\n",
       "      <td>-0.023458</td>\n",
       "      <td>-0.023676</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>-0.008224</td>\n",
       "      <td>0.022538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.317884</td>\n",
       "      <td>0.573845</td>\n",
       "      <td>0.572969</td>\n",
       "      <td>0.573687</td>\n",
       "      <td>0.547715</td>\n",
       "      <td>0.577876</td>\n",
       "      <td>0.560909</td>\n",
       "      <td>0.581518</td>\n",
       "      <td>0.575805</td>\n",
       "      <td>0.554861</td>\n",
       "      <td>0.587826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-28.571479</td>\n",
       "      <td>-0.991959</td>\n",
       "      <td>-0.998194</td>\n",
       "      <td>-0.999324</td>\n",
       "      <td>-0.998201</td>\n",
       "      <td>-0.995032</td>\n",
       "      <td>-0.999613</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>-0.994230</td>\n",
       "      <td>-0.997543</td>\n",
       "      <td>-0.999293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.749023</td>\n",
       "      <td>-0.470222</td>\n",
       "      <td>-0.465985</td>\n",
       "      <td>-0.458986</td>\n",
       "      <td>-0.404503</td>\n",
       "      <td>-0.564319</td>\n",
       "      <td>-0.500674</td>\n",
       "      <td>-0.452536</td>\n",
       "      <td>-0.490749</td>\n",
       "      <td>-0.479613</td>\n",
       "      <td>-0.510760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.342257</td>\n",
       "      <td>0.054528</td>\n",
       "      <td>0.063471</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>-0.020137</td>\n",
       "      <td>-0.038920</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.013866</td>\n",
       "      <td>0.048041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.314491</td>\n",
       "      <td>0.502561</td>\n",
       "      <td>0.546586</td>\n",
       "      <td>0.522895</td>\n",
       "      <td>0.521285</td>\n",
       "      <td>0.455003</td>\n",
       "      <td>0.443305</td>\n",
       "      <td>0.514832</td>\n",
       "      <td>0.545585</td>\n",
       "      <td>0.448593</td>\n",
       "      <td>0.519058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.783832</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.994922</td>\n",
       "      <td>0.991773</td>\n",
       "      <td>0.997404</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.999567</td>\n",
       "      <td>0.993866</td>\n",
       "      <td>0.991769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label   feature#0   feature#1   feature#2   feature#3   feature#4  \\\n",
       "count  501.000000  501.000000  501.000000  501.000000  501.000000  501.000000   \n",
       "mean     0.256889    0.018333    0.028086    0.018247    0.057697   -0.023458   \n",
       "std     10.317884    0.573845    0.572969    0.573687    0.547715    0.577876   \n",
       "min    -28.571479   -0.991959   -0.998194   -0.999324   -0.998201   -0.995032   \n",
       "25%     -6.749023   -0.470222   -0.465985   -0.458986   -0.404503   -0.564319   \n",
       "50%      0.342257    0.054528    0.063471    0.007159    0.099202   -0.020137   \n",
       "75%      7.314491    0.502561    0.546586    0.522895    0.521285    0.455003   \n",
       "max     27.783832    0.999022    0.999009    0.994922    0.991773    0.997404   \n",
       "\n",
       "        feature#5   feature#6   feature#7   feature#8   feature#9  \n",
       "count  501.000000  501.000000  501.000000  501.000000  501.000000  \n",
       "mean    -0.023676    0.012449    0.024423   -0.008224    0.022538  \n",
       "std      0.560909    0.581518    0.575805    0.554861    0.587826  \n",
       "min     -0.999613   -0.994820   -0.994230   -0.997543   -0.999293  \n",
       "25%     -0.500674   -0.452536   -0.490749   -0.479613   -0.510760  \n",
       "50%     -0.038920    0.014495    0.002067   -0.013866    0.048041  \n",
       "75%      0.443305    0.514832    0.545585    0.448593    0.519058  \n",
       "max      0.999391    0.999294    0.999567    0.993866    0.991769  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Estimator\n",
      "\n",
      "Fit the model\n",
      "\n",
      "Coefficients:\n",
      "[0.0,0.32292516677405936,-0.3438548034562218,1.9156017023458414,0.05288058680386263,0.765962720459771,0.0,-0.15105392669186682,-0.21587930360904642,0.22025369188813426]\n",
      "\n",
      "Intercept:\n",
      "0.159893684424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_linear_regression_data.txt\")\n",
    "\n",
    "# schema\n",
    "print \"schema:\"\n",
    "training.printSchema()\n",
    "\n",
    "# summarizing the label\n",
    "#print \"label summary:\"\n",
    "#training.select('label').summary().show()\n",
    "\n",
    "# summarizing the features\n",
    "#print \"features summary:\"\n",
    "#from pyspark.ml.stat import Summarizer\n",
    "#summarizer = Summarizer.metrics('mean', 'variance', 'count', 'numNonZeros', 'max', 'min', 'normL2', 'normL1')\n",
    "#training.select(summarizer.summary(training['features'])).show(truncate=False)\n",
    "\n",
    "# preprocess\n",
    "training2 = training\n",
    "def func(v):\n",
    "    return v.values.tolist()[0]\n",
    "udf_func = F.udf(func)\n",
    "for i in range(10):\n",
    "    outputCol = \"feature#{}\".format(i)\n",
    "    vs = VectorSlicer(inputCol=\"features\", outputCol=outputCol, indices=[i])\n",
    "    training2 = vs.transform(training2)\n",
    "    training2 = training2.withColumn(outputCol, udf_func(outputCol).cast('double'))\n",
    "training2 = training2.drop('features')\n",
    "pandas_df = training2.toPandas()\n",
    "\n",
    "print \"data:\"\n",
    "display(pandas_df.head())\n",
    "\n",
    "print \"summary:\"\n",
    "display(pandas_df.describe())\n",
    "\n",
    "# create estimator\n",
    "print \"Create Estimator\\n\"\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label', predictionCol='prediction', \n",
    "                      maxIter=10, regParam=0.3, elasticNetParam=0.8, tol=1e-06, fitIntercept=True, \n",
    "                      standardization=True, solver='normal', aggregationDepth=2, loss='squaredError')\n",
    "\n",
    "# Fit the model\n",
    "print \"Fit the model\\n\"\n",
    "model = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print \"Coefficients:\\n{}\\n\".format(model.coefficients)\n",
    "print \"Intercept:\\n{}\\n\".format(model.intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of freedom:\n",
      "490\n",
      "\n",
      "devianceResiduals:\n",
      "[-28.20701032917172, 27.44330383186209]\n",
      "\n",
      "explainedVariance:\n",
      "1.34436653782\n",
      "\n",
      "meanAbsoluteError:\n",
      "8.18285041011\n",
      "\n",
      "meanSquaredError:\n",
      "103.817293527\n",
      "\n",
      "numInstances:\n",
      "501\n",
      "\n",
      "objectiveHistory:\n",
      "[0.49999999999999994, 0.4967620357443381, 0.4936361664340463, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n",
      "\n",
      "predictions:\n",
      "\n",
      "+-------------------+--------------------+--------------------+\n",
      "|              label|            features|          prediction|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...| 0.39922280427864854|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|-0.29559741764686487|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|  0.7651496483023066|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|  0.7839239258929726|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|  1.4831466765011345|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...| -0.9871618140066576|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|  1.5395124755034428|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...| 0.05906145957465214|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...| -2.0397390816430665|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|  2.1211666677165093|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|-0.04572650153420729|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|  1.4045706595369045|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|  1.8936490662233862|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|  0.2625495742873283|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|  1.1054144970959854|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...| -1.3003908887799676|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...| -2.0446543261749612|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|  -0.960287000485595|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|  1.6330567770307318|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|  1.1299316224433398|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "r2:\n",
      "0.022861466914\n",
      "\n",
      "r2adj:\n",
      "0.00291986419792\n",
      "\n",
      "Residuals:\n",
      "\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  -9.889232683103197|\n",
      "|  0.5533794340053554|\n",
      "|  -5.204019455758823|\n",
      "| -20.566686715507508|\n",
      "|    -9.4497405180564|\n",
      "|  -6.909112502719486|\n",
      "|  -10.00431602969873|\n",
      "|   2.062397807050484|\n",
      "|  3.1117508432954772|\n",
      "| -15.893608229419382|\n",
      "|  -5.036284254673026|\n",
      "|   6.483215876994333|\n",
      "|  12.429497299109002|\n",
      "|  -20.32003219007654|\n",
      "| -2.0049838218725005|\n",
      "| -17.867901734183793|\n",
      "|   7.646455887420495|\n",
      "| -2.2653482182417406|\n",
      "|-0.10308920436195645|\n",
      "|  -1.380034070385301|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE:\n",
      "10.1890771676\n",
      "\n",
      "totalIterations:\n",
      "7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model over the training set and print out some metrics\n",
    "traningSummary = model.summary\n",
    "\n",
    "# Standard error of estimated coefficients and intercept. This value is only available when using the “normal” solver.\n",
    "#print \"Coefficient Standard Errors:\\n{}\\n\".format(summary.coefficientStandardErrors)\n",
    "\n",
    "# Degrees of freedom.\n",
    "print \"Degrees of freedom:\\n{}\\n\".format(traningSummary.degreesOfFreedom)\n",
    "\n",
    "# The weighted residuals, the usual residuals rescaled by the square root of the instance weights.\n",
    "print \"devianceResiduals:\\n{}\\n\".format(traningSummary.devianceResiduals)\n",
    "\n",
    "# Returns the explained variance regression score. explainedVariance = 1−𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝑦−𝑦̂ )𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝑦)\n",
    "print \"explainedVariance:\\n{}\\n\".format(traningSummary.explainedVariance)\n",
    "\n",
    "# Returns the mean absolute error, which is a risk function corresponding to the expected value of the absolute error loss or l1-norm loss.\n",
    "print \"meanAbsoluteError:\\n{}\\n\".format(traningSummary.meanAbsoluteError)\n",
    "\n",
    "# Returns the mean squared error, which is a risk function corresponding to the expected value of the squared error loss or quadratic loss.\n",
    "print \"meanSquaredError:\\n{}\\n\".format(traningSummary.meanSquaredError)\n",
    "\n",
    "# Number of instances in DataFrame predictions\n",
    "print \"numInstances:\\n{}\\n\".format(traningSummary.numInstances)\n",
    "\n",
    "# Objective function (scaled loss + regularization) at each iteration\n",
    "print \"objectiveHistory:\\n{}\\n\".format(traningSummary.objectiveHistory)\n",
    "\n",
    "# Two-sided p-value of estimated coefficients and intercept. This value is only available when using the “normal” solver.\n",
    "#print \"pValues:\\n{}\\n\".format(traningSummary.pValues)\n",
    "\n",
    "# Dataframe outputted by the model’s transform method.\n",
    "print \"predictions:\\n\"; traningSummary.predictions.show()\n",
    "\n",
    "# Returns R^2, the coefficient of determination.\n",
    "print \"r2:\\n{}\\n\".format(traningSummary.r2)\n",
    "\n",
    "# Returns Adjusted R^2, the adjusted coefficient of determination.\n",
    "print \"r2adj:\\n{}\\n\".format(traningSummary.r2adj)\n",
    "\n",
    "# Residuals (label - predicted value)\n",
    "print \"Residuals:\\n\"; traningSummary.residuals.show()\n",
    "\n",
    "# Returns the root mean squared error, which is defined as the square root of the mean squared error.\n",
    "print \"RMSE:\\n{}\\n\".format(traningSummary.rootMeanSquaredError)\n",
    "\n",
    "# T-statistic of estimated coefficients and intercept. This value is only available when using the “normal” solver.\n",
    "#print \"tValues:\\n{}\\n\".format(traningSummary.tValues)\n",
    "\n",
    "# Number of training iterations until termination. This value is only available when using the “l-bfgs” solver.\n",
    "print \"totalIterations:\\n{}\\n\".format(traningSummary.totalIterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of freedom:\n",
      "490\n",
      "\n",
      "devianceResiduals:\n",
      "[-28.20701032917172, 27.44330383186209]\n",
      "\n",
      "explainedVariance:\n",
      "1.34436653782\n",
      "\n",
      "meanAbsoluteError:\n",
      "8.18285041011\n",
      "\n",
      "meanSquaredError:\n",
      "103.817293527\n",
      "\n",
      "numInstances:\n",
      "501\n",
      "\n",
      "predictions:\n",
      "\n",
      "+-------------------+--------------------+--------------------+\n",
      "|              label|            features|          prediction|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...| 0.39922280427864854|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|-0.29559741764686487|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|  0.7651496483023066|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|  0.7839239258929726|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|  1.4831466765011345|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...| -0.9871618140066576|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|  1.5395124755034428|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...| 0.05906145957465214|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...| -2.0397390816430665|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|  2.1211666677165093|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|-0.04572650153420729|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|  1.4045706595369045|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|  1.8936490662233862|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|  0.2625495742873283|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|  1.1054144970959854|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...| -1.3003908887799676|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...| -2.0446543261749612|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|  -0.960287000485595|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|  1.6330567770307318|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|  1.1299316224433398|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "r2:\n",
      "0.022861466914\n",
      "\n",
      "r2adj:\n",
      "0.00291986419792\n",
      "\n",
      "Residuals:\n",
      "\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  -9.889232683103197|\n",
      "|  0.5533794340053554|\n",
      "|  -5.204019455758823|\n",
      "| -20.566686715507508|\n",
      "|    -9.4497405180564|\n",
      "|  -6.909112502719486|\n",
      "|  -10.00431602969873|\n",
      "|   2.062397807050484|\n",
      "|  3.1117508432954772|\n",
      "| -15.893608229419382|\n",
      "|  -5.036284254673026|\n",
      "|   6.483215876994333|\n",
      "|  12.429497299109002|\n",
      "|  -20.32003219007654|\n",
      "| -2.0049838218725005|\n",
      "| -17.867901734183793|\n",
      "|   7.646455887420495|\n",
      "| -2.2653482182417406|\n",
      "|-0.10308920436195645|\n",
      "|  -1.380034070385301|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE:\n",
      "10.1890771676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluates the model on a test dataset.\n",
    "summary = model.evaluate(training) # just for demonstration!!!\n",
    "\n",
    "# Standard error of estimated coefficients and intercept. This value is only available when using the “normal” solver.\n",
    "#print \"Coefficient Standard Errors:\\n{}\\n\".format(summary.coefficientStandardErrors)\n",
    "\n",
    "# Degrees of freedom.\n",
    "print \"Degrees of freedom:\\n{}\\n\".format(summary.degreesOfFreedom)\n",
    "\n",
    "# The weighted residuals, the usual residuals rescaled by the square root of the instance weights.\n",
    "print \"devianceResiduals:\\n{}\\n\".format(summary.devianceResiduals)\n",
    "\n",
    "# Returns the explained variance regression score. explainedVariance = 1−𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝑦−𝑦̂ )𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝑦)\n",
    "print \"explainedVariance:\\n{}\\n\".format(summary.explainedVariance)\n",
    "\n",
    "# Returns the mean absolute error, which is a risk function corresponding to the expected value of the absolute error loss or l1-norm loss.\n",
    "print \"meanAbsoluteError:\\n{}\\n\".format(summary.meanAbsoluteError)\n",
    "\n",
    "# Returns the mean squared error, which is a risk function corresponding to the expected value of the squared error loss or quadratic loss.\n",
    "print \"meanSquaredError:\\n{}\\n\".format(summary.meanSquaredError)\n",
    "\n",
    "# Number of instances in DataFrame predictions\n",
    "print \"numInstances:\\n{}\\n\".format(summary.numInstances)\n",
    "\n",
    "# Two-sided p-value of estimated coefficients and intercept. This value is only available when using the “normal” solver.\n",
    "#print \"pValues:\\n{}\\n\".format(summary.pValues)\n",
    "\n",
    "# Dataframe outputted by the model’s transform method.\n",
    "print \"predictions:\\n\"; summary.predictions.show()\n",
    "\n",
    "# Returns R^2, the coefficient of determination.\n",
    "print \"r2:\\n{}\\n\".format(summary.r2)\n",
    "\n",
    "# Returns Adjusted R^2, the adjusted coefficient of determination.\n",
    "print \"r2adj:\\n{}\\n\".format(summary.r2adj)\n",
    "\n",
    "# Residuals (label - predicted value)\n",
    "print \"Residuals:\\n\"; summary.residuals.show()\n",
    "\n",
    "# Returns the root mean squared error, which is defined as the square root of the mean squared error.\n",
    "print \"RMSE:\\n{}\\n\".format(summary.rootMeanSquaredError)\n",
    "\n",
    "# T-statistic of estimated coefficients and intercept. This value is only available when using the “normal” solver.\n",
    "#print \"tValues:\\n{}\\n\".format(summary.tValues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|              label|            features|          prediction|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...| 0.39922280427864854|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|-0.29559741764686487|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|  0.7651496483023066|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|  0.7839239258929726|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|  1.4831466765011345|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...| -0.9871618140066576|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|  1.5395124755034428|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...| 0.05906145957465214|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...| -2.0397390816430665|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|  2.1211666677165093|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|-0.04572650153420729|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|  1.4045706595369045|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|  1.8936490662233862|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|  0.2625495742873283|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|  1.1054144970959854|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...| -1.3003908887799676|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...| -2.0446543261749612|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|  -0.960287000485595|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|  1.6330567770307318|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|  1.1299316224433398|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(training) # just for demonstration!!!\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalized Linear Regression\n",
    "- A flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.\n",
    "- Generalizes linear regression by allowing the linear model to be related to the response(dependent) variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
    "- Fit a Generalized Linear Model specified by giving the linear predictor (link function) and the error distribution (family).\n",
    "- Valid link functions for each family are listed below.\n",
    "\n",
    "| family     | link functions                                              | default |\n",
    "|:-----------|:------------------------------------------------------------|:--------|\n",
    "| gaussian   | identity, log, inverse                                      | identity|\n",
    "| binomial   | logit, probit, cloglog                                      | logit   |\n",
    "| poisson    | log, identity, sqrt                                         | log     |\n",
    "| gamma      | inverse, identity, log                                      | inverse |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Estimator\n",
      "\n",
      "Coefficients:\n",
      "[0.010541828081257216,0.8003253100560949,-0.7845165541420371,2.3679887171421914,0.5010002089857577,1.1222351159753026,-0.2926824398623296,-0.49837174323213035,-0.6035797180675657,0.6725550067187461]\n",
      "\n",
      "Intercept:\n",
      "0.145921761452\n",
      "\n",
      "Coefficient Standard Errors:\n",
      "[0.7950428434287478, 0.8049713176546897, 0.7975916824772489, 0.8312649247659919, 0.7945436200517938, 0.8118992572197593, 0.7919506385542777, 0.7973378214726764, 0.8300714999626418, 0.7771333489686802, 0.463930109648428]\n",
      "\n",
      "T Values:\n",
      "[0.013259446542269243, 0.9942283563442594, -0.9836067393599172, 2.848657084633759, 0.6305509179635714, 1.382234441029355, -0.3695715687490668, -0.6250446546128238, -0.7271418403049983, 0.8654306337661122, 0.31453393176593286]\n",
      "\n",
      "P Values:\n",
      "[0.989426199114056, 0.32060241580811044, 0.3257943227369877, 0.004575078538306521, 0.5286281628105467, 0.16752945248679119, 0.7118614002322872, 0.5322327097421431, 0.467486325282384, 0.3872259825794293, 0.753249430501097]\n",
      "\n",
      "Dispersion:\n",
      "105.609883568\n",
      "\n",
      "Residual Degree Of Freedom Null:\n",
      "500\n",
      "\n",
      "Residual Degree Of Freedom:\n",
      "490\n",
      "\n",
      "AIC(An Information Criterion):\n",
      "3769.18958718\n",
      "\n",
      "Deviance:\n",
      "51748.8429484\n",
      "\n",
      "Null Deviance:\n",
      "53229.3654339\n",
      "\n",
      "Deviance Residuals: \n",
      "+-------------------+\n",
      "|  devianceResiduals|\n",
      "+-------------------+\n",
      "|-10.974359174246889|\n",
      "| 0.8872320138420559|\n",
      "| -4.596541837478908|\n",
      "|-20.411667435019638|\n",
      "|-10.270419345342642|\n",
      "|-6.0156058956799905|\n",
      "|-10.663939415849267|\n",
      "| 2.1153960525024713|\n",
      "| 3.9807132379137675|\n",
      "|-17.225218272069533|\n",
      "| -4.611647633532147|\n",
      "| 6.4176669407698546|\n",
      "| 11.407137945300537|\n",
      "| -20.70176540467664|\n",
      "| -2.683748540510967|\n",
      "|-16.755494794232536|\n",
      "|  8.154668342638725|\n",
      "|-1.4355057987358848|\n",
      "|-0.6435058688185704|\n",
      "|  -1.13802589316832|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Load training data\n",
    "dataset = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_linear_regression_data.txt\")\n",
    "\n",
    "# create estimator\n",
    "print \"Create Estimator\\n\"\n",
    "glr = GeneralizedLinearRegression(labelCol='label', featuresCol='features', predictionCol='prediction', \n",
    "                                  family='gaussian', link='identity', \n",
    "                                  maxIter=25, regParam=0.3, tol=1e-06, fitIntercept=True, solver='irls')\n",
    "#                                  linkPredictionCol=None, variancePower=0.0, linkPower=None, offsetCol=None)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(dataset)\n",
    "\n",
    "# Print the coefficients and intercept for generalized linear regression model\n",
    "print \"Coefficients:\\n{}\\n\".format(model.coefficients)\n",
    "print \"Intercept:\\n{}\\n\".format(model.intercept)\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "print \"Coefficient Standard Errors:\\n{}\\n\".format(summary.coefficientStandardErrors)\n",
    "print \"T Values:\\n{}\\n\".format(summary.tValues)\n",
    "print \"P Values:\\n{}\\n\".format(summary.pValues)\n",
    "print \"Dispersion:\\n{}\\n\".format(summary.dispersion)\n",
    "print \"Residual Degree Of Freedom Null:\\n{}\\n\".format(summary.residualDegreeOfFreedomNull)\n",
    "print \"Residual Degree Of Freedom:\\n{}\\n\".format(summary.residualDegreeOfFreedom)\n",
    "print \"AIC(An Information Criterion):\\n{}\\n\".format(summary.aic)\n",
    "print \"Deviance:\\n{}\\n\".format(summary.deviance)\n",
    "print \"Null Deviance:\\n{}\\n\".format(summary.nullDeviance)\n",
    "print(\"Deviance Residuals: \")\n",
    "summary.residuals().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "pyspark.ml.classification module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binomial logistic regression\n",
    "note : coefficients and intercept methods on a logistic regression model trained with multinomial family are not supported. Use coefficientMatrix and interceptVector instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Coefficients: (692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.353983524188197e-05,-9.102738505589466e-05,-0.00019467430546904298,-0.00020300642473486668,-3.1476183314863995e-05,-6.842977602660743e-05,1.5883626898239883e-05,1.4023497091372047e-05,0.00035432047524968605,0.00011443272898171087,0.00010016712383666666,0.0006014109303795481,0.0002840248179122762,-0.00011541084736508837,0.000385996886312906,0.000635019557424107,-0.00011506412384575676,-0.00015271865864986808,0.0002804933808994214,0.0006070117471191634,-0.0002008459663247437,-0.0001421075579290126,0.0002739010341160883,0.00027730456244968115,-9.838027027269332e-05,-0.0003808522443517704,-0.00025315198008555033,0.00027747714770754307,-0.0002443619763919199,-0.0015394744687597765,-0.00023073328411331293])\n",
      "Intercept: 0.224563159613\n",
      "Multinomial coefficients: 2 X 692 CSRMatrix\n",
      "(0,244) 0.0\n",
      "(0,263) 0.0001\n",
      "(0,272) 0.0001\n",
      "(0,300) 0.0001\n",
      "(0,350) -0.0\n",
      "(0,351) -0.0\n",
      "(0,378) -0.0\n",
      "(0,379) -0.0\n",
      "(0,405) -0.0\n",
      "(0,406) -0.0006\n",
      "(0,407) -0.0001\n",
      "(0,428) 0.0001\n",
      "(0,433) -0.0\n",
      "(0,434) -0.0007\n",
      "(0,455) 0.0001\n",
      "(0,456) 0.0001\n",
      "..\n",
      "..\n",
      "Multinomial intercepts: [-0.12065879445860686,0.12065879445860686]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "training.show()\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.98\n",
      "ROC:\n",
      "+---+--------------------+\n",
      "|FPR|                 TPR|\n",
      "+---+--------------------+\n",
      "|0.0|                 0.0|\n",
      "|0.0|0.017543859649122806|\n",
      "|0.0| 0.03508771929824561|\n",
      "|0.0| 0.05263157894736842|\n",
      "|0.0| 0.07017543859649122|\n",
      "|0.0| 0.08771929824561403|\n",
      "|0.0| 0.10526315789473684|\n",
      "|0.0| 0.12280701754385964|\n",
      "|0.0| 0.14035087719298245|\n",
      "|0.0| 0.15789473684210525|\n",
      "|0.0| 0.17543859649122806|\n",
      "|0.0| 0.19298245614035087|\n",
      "|0.0| 0.21052631578947367|\n",
      "|0.0| 0.22807017543859648|\n",
      "|0.0| 0.24561403508771928|\n",
      "|0.0|  0.2631578947368421|\n",
      "|0.0|  0.2807017543859649|\n",
      "|0.0|  0.2982456140350877|\n",
      "|0.0|  0.3157894736842105|\n",
      "|0.0|  0.3333333333333333|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 1.0\n",
      "fMeasureByLabel: [0.9761904761904763, 0.9827586206896551]\n",
      "fMeasureByThreshold:\n",
      "+------------------+--------------------+\n",
      "|         threshold|           F-Measure|\n",
      "+------------------+--------------------+\n",
      "|0.7845860015371142|0.034482758620689655|\n",
      "|0.7843193344168922| 0.06779661016949151|\n",
      "|0.7842976092510131|                 0.1|\n",
      "|0.7842531051133191| 0.13114754098360656|\n",
      "|0.7835792429453297| 0.16129032258064516|\n",
      "|0.7835223585829078|  0.1904761904761905|\n",
      "| 0.783284563364102|             0.21875|\n",
      "|0.7832449070254992| 0.24615384615384614|\n",
      "|0.7830630257264691|  0.2727272727272727|\n",
      "|0.7830068256743365| 0.29850746268656714|\n",
      "|0.7822341175907138|  0.3235294117647059|\n",
      "| 0.782111826902122| 0.34782608695652173|\n",
      "| 0.781220790993743|  0.3714285714285714|\n",
      "|0.7802700864854707|  0.3943661971830986|\n",
      "|0.7789683616171501|  0.4166666666666667|\n",
      "|0.7789606764592472|  0.4383561643835616|\n",
      "|0.7788060694625324| 0.45945945945945943|\n",
      "|0.7783754276111222|  0.4799999999999999|\n",
      "|0.7771658291080574|                 0.5|\n",
      "|0.7769914303593917|  0.5194805194805194|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "falsePositiveRateByLabel: [0.0, 0.046511627906976744]\n",
      "labels: [0.0, 1.0]\n",
      "objectiveHistory:\n",
      "0.683314913574\n",
      "0.666287575147\n",
      "0.621706854603\n",
      "0.612726524589\n",
      "0.60603479868\n",
      "0.603175068757\n",
      "0.596962153484\n",
      "0.594074303198\n",
      "0.590608924334\n",
      "0.589472457649\n",
      "0.588218777573\n",
      "precision-recall curve:\n",
      "+--------------------+---------+\n",
      "|              recall|precision|\n",
      "+--------------------+---------+\n",
      "|                 0.0|      1.0|\n",
      "|0.017543859649122806|      1.0|\n",
      "| 0.03508771929824561|      1.0|\n",
      "| 0.05263157894736842|      1.0|\n",
      "| 0.07017543859649122|      1.0|\n",
      "| 0.08771929824561403|      1.0|\n",
      "| 0.10526315789473684|      1.0|\n",
      "| 0.12280701754385964|      1.0|\n",
      "| 0.14035087719298245|      1.0|\n",
      "| 0.15789473684210525|      1.0|\n",
      "| 0.17543859649122806|      1.0|\n",
      "| 0.19298245614035087|      1.0|\n",
      "| 0.21052631578947367|      1.0|\n",
      "| 0.22807017543859648|      1.0|\n",
      "| 0.24561403508771928|      1.0|\n",
      "|  0.2631578947368421|      1.0|\n",
      "|  0.2807017543859649|      1.0|\n",
      "|  0.2982456140350877|      1.0|\n",
      "|  0.3157894736842105|      1.0|\n",
      "|  0.3333333333333333|      1.0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "print \"accuracy:\", trainingSummary.accuracy\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "print \"ROC:\"\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "print \"fMeasureByLabel:\", trainingSummary.fMeasureByLabel()\n",
    "\n",
    "print \"fMeasureByThreshold:\"\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "fMeasure.show()\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)\n",
    "\n",
    "print \"falsePositiveRateByLabel:\", trainingSummary.falsePositiveRateByLabel\n",
    "\n",
    "print \"labels:\", trainingSummary.labels\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "print(\"precision-recall curve:\")\n",
    "trainingSummary.pr.show()\n",
    "\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial logistic regression\n",
    "- This is supported via multinomial logistic (`softmax`) regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "3 X 4 CSRMatrix\n",
      "(0,3) 0.3176\n",
      "(1,2) -0.7804\n",
      "(1,3) -0.377\n",
      "Intercept: [0.05165231659832854,-0.12391224990853622,0.07225993331020768]\n",
      "objectiveHistory:\n",
      "1.09861228867\n",
      "1.08760208544\n",
      "1.03411565722\n",
      "1.02898595203\n",
      "1.03003896574\n",
      "1.02399651582\n",
      "1.02360974518\n",
      "1.0231082122\n",
      "1.0230222203\n",
      "1.02300181518\n",
      "1.02299637396\n",
      "False positive rate by label:\n",
      "label 0: 0.22\n",
      "label 1: 0.05\n",
      "label 2: 0.0\n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 0.46\n",
      "Precision by label:\n",
      "label 0: 0.694444444444\n",
      "label 1: 0.909090909091\n",
      "label 2: 1.0\n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 0.46\n",
      "F-measure by label:\n",
      "label 0: 0.819672131148\n",
      "label 1: 0.952380952381\n",
      "label 2: 0.630136986301\n",
      "Accuracy: 0.82\n",
      "FPR: 0.09\n",
      "TPR: 0.82\n",
      "F-measure: 0.800730023277\n",
      "Precision: 0.867845117845\n",
      "Recall: 0.82\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark \\\n",
    "    .read \\\n",
    "    .format(\"libsvm\") \\\n",
    "    .load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Machine Classifier\n",
    "- This binary classifier optimizes the Hinge Loss using the OWLQN optimizer.\n",
    "- Only supports L2 regularization currently.\n",
    "- Support only binary classification with linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n",
      "2\n",
      "Coefficients: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0005170630317473439,-0.0001172288654973735,-8.882754836918948e-05,8.522360710187464e-05,0.0,0.0,-1.3436361263314267e-05,0.0003729569801338091,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0008888949552633658,0.00029864059761812683,0.0003793378816193159,-0.0001762328898254081,0.0,1.5028489269747836e-06,1.8056041144946687e-06,1.8028763260398597e-06,-3.3843713506473646e-06,-4.041580184807502e-06,2.0965017727015125e-06,8.536111642989494e-05,0.00022064177429604464,0.00021677599940575452,-0.0005472401396558763,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000921415502407147,0.00031351066886882195,0.0002481984318412822,0.0,-4.147738197636148e-05,-3.6832150384497175e-05,0.0,-3.9652366184583814e-06,-5.1569169804965594e-05,-6.624697287084958e-05,-2.182148650424713e-05,1.163442969067449e-05,-1.1535211416971104e-06,3.8138960488857075e-05,1.5823711634321492e-06,-4.784013432336632e-05,-9.386493224111833e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00043174897827077767,0.00017055492867397665,0.0,-2.7978204136148868e-05,-5.88745220385208e-05,-4.1858794529775e-05,-3.740692964881002e-05,-3.9787939304887e-05,-5.545881895011037e-05,-4.505015598421474e-05,-3.214002494749943e-06,-1.6561868808274739e-06,-4.416063987619447e-06,-7.9986183315327e-06,-4.729962112535003e-05,-2.516595625914463e-05,-3.6407809279248066e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00024719098130614967,0.0,-3.270637431382939e-05,-5.5703407875748054e-05,-5.2336892125702286e-05,-7.829604482365818e-05,-7.60385448387619e-05,-8.371051301348216e-05,-1.8669558753795108e-05,0.0,1.2045309486213725e-05,-2.3374084977016397e-05,-1.0788641688879534e-05,-5.5731194431606874e-05,-7.952979033591137e-05,-1.4529196775456057e-05,8.737948348132623e-06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0012589360772978808,-0.0001816228630214369,-0.00010650711664557365,-6.040355527710781e-05,-4.856392973921569e-05,-8.973895954652451e-05,-8.78131677062384e-05,-5.68487774673792e-05,-3.780926734276347e-05,1.3834897036553787e-05,7.585485129441565e-05,5.5017411816753975e-05,-1.5430755398169695e-05,-1.834928703625931e-05,-0.00010354008265646844,-0.00013527847721351194,-0.00011245007647684532,-2.9373916056750564e-05,-7.311217847336934e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0002858228613863785,-0.00012998173971449976,-0.0001478408021316135,-8.203374605865772e-05,-6.556685320008032e-05,-5.6392660386580244e-05,-6.995571627330911e-05,-4.664348159856693e-05,-2.3026593698824318e-05,7.398833979172035e-05,0.00014817176130099997,0.00010938317435545486,7.940425167011364e-05,-6.743294804348106e-07,-0.00012623302721464762,-0.00019110387355357616,-0.00018611622108961136,-0.00012776766254736952,-8.935302806524433e-05,-1.239417230441996e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0002829530831354112,-0.00013912189600461263,-0.00012593136464577562,-5.964745187930992e-05,-5.360328152341982e-05,-0.00010517880662090183,-0.00013856124131005022,-7.181032974125911e-05,2.3249038865093483e-06,0.0001566964269571967,0.00023261206954040812,0.00017261638232256968,0.00013857530960270466,-1.396299028868332e-05,-0.00015765773982418597,-0.00020728798812007546,-0.00019106441272002828,-0.00012744834161431415,-0.00012755611630280015,-5.1885591560478935e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.000159081567023441,-0.0001216531230287931,-5.623851079809818e-05,-3.877987126382982e-05,-7.550900509956966e-05,-0.00010703140005463545,-0.00014720428138106226,-8.781423374509368e-05,7.941655609421792e-05,0.00023206354986219992,0.00027506982343672394,0.0002546722233188043,0.0001810821666388498,-1.3069916689929984e-05,-0.0001842374220886751,-0.0001977540482445517,-0.00017722074063670741,-0.0001487987014723575,-0.00011879021431288621,-9.755283887790393e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0001302740311359312,-5.3683030235535024e-05,-1.7631200013656873e-05,-7.846611034608254e-05,-0.000122100767283256,-0.00017281968533449702,-0.00015592346128894157,-5.239579492910452e-05,0.0001680719343542442,0.00028930086786548053,0.0003629921493231646,0.0002958223512266975,0.00021770466955449064,-6.40884808188951e-05,-0.00019058225556007997,-0.00020425138564600712,-0.0001711994903702119,-0.00013853486798341369,-0.00013018592950855062,-0.00011887779512760102,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-7.021411112285498e-05,-1.694500843168125e-05,-7.189722824172193e-05,-0.00014560828004346436,-0.00014935497340563198,-0.00019496419340776972,-0.00017383743417254187,-3.3438825792010694e-05,0.0002866538327947017,0.00029812321570739803,0.000377250607691119,0.0003211702827486386,0.0002577995115175486,-0.00016627385656703205,-0.00018037105851523224,-0.00020419356344211325,-0.00017962237203420184,-0.00013726488083579862,-0.00013461014473741762,-0.00012264216469164138,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0015239752514658556,-5.472330865993813e-05,-9.65684394936216e-05,-0.00013424729853486994,-0.00014727467799568,-0.0001616270978824712,-0.00018458259010029364,-0.00019699647135089726,0.00013085261294290817,0.0002943178857107149,0.0003097773692834126,0.0004112834769312103,0.00034113620757035025,0.00016529945924367265,-0.00021065410862650534,-0.0001883924081539624,-0.0001979586414569358,-0.0001762131187223702,-0.0001272343622678854,-0.00012708161719220297,-0.00014812221011889967,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.001140680600536578,-0.0001323467421269896,-0.00012904607854274846,-0.00014104748544921958,-0.00015194605434027872,-0.00021104539389774283,-0.00017911827582001795,-0.00018952948277194435,0.00021767571552539842,0.00030201791656326465,0.0004002863274397723,0.00040322806756364006,0.0004118077382608461,3.7917405252859545e-06,-0.00019886290660234838,-0.00019547443112937263,-0.00019857348218680872,-0.00013336892200703206,-0.00012830129292910815,-0.00011855916317355505,-0.0001765597203760205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0010938769592297973,-0.00012785475305234688,-0.00013424699777466666,-0.0001505200652479287,-0.00019333287822872713,-0.00020385160086594937,-0.00017422470698847553,4.63598443910652e-05,0.00020617623087127652,0.0002862882891134514,0.0004074830988361515,0.0003726357785147985,0.0003507520190729629,-0.0001516485494364312,-0.00017053751921469217,-0.00019638964654350848,-0.00019962586265806435,-0.00013612312664311173,-0.0001218285533892454,-0.00011166712081624676,-0.0001377283888177579,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0003044386260118809,-0.0001240836643202059,-0.0001335317492716633,-0.00015783442604618277,-0.00019168434243384107,-0.00018710322733892716,-0.00011283989231463139,0.00011136504453105364,0.00018707244892705632,0.00028654279528966305,0.00040032117544983536,0.0003169637536305377,0.00020158994278679014,-0.00013139392844616033,-0.00015181070482383948,-0.0001825431845981843,-0.0001602539928567571,-0.00013230404795396355,-0.00011669138691257469,-0.00010532154964150405,-0.00013709037042366007,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00040287410145021705,-0.00013563987950912995,-0.00013225887084018914,-0.00016523502389794188,-0.00020175074284706945,-0.0001572459106394481,2.577536501278673e-06,0.0001312463663419457,0.00020707422291927531,0.00039081065544314936,0.00033487058329898135,0.00025790441367156086,2.6881819648016494e-05,-0.0001511383586714907,-0.0001605428139328567,-0.00017267287462873575,-0.00011938943768052963,-0.00010505245038633314,-0.00011109385509034013,-0.00013469914274864725,-0.00020735223736035555,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0005034374233912422,-0.00015961213688405883,-0.0001274222123810994,-0.0001582821104884909,-0.00021301220616286252,-0.00012933366375029613,1.6802673102179614e-05,0.00011020918082727098,0.00021160795272688753,0.00034873421050827716,0.00026487211944380384,0.0001151606835026639,-5.4682731396851946e-05,-0.00013632001630934325,-0.00014340405857651405,-0.0001248695773821634,-8.462873247977974e-05,-9.580708414770257e-05,-0.00010749166605399431,-0.00014618038459197777,-0.00037556446296204636,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0005124342611878493,-0.00020369734099093433,-0.00013626985098328694,-0.00013313768183302705,-0.0001871555537819396,-0.0001188817315789655,-1.8774817595622694e-05,5.7108412194993384e-05,0.00012728161056121406,0.00019021458214915667,0.00012177397895874969,-1.2461153574281128e-05,-7.553961810487739e-05,-0.00010242174559410404,-4.44873554195981e-05,-9.058561577961895e-05,-6.837347198855518e-05,-8.084409304255458e-05,-0.00013316868299585082,-0.00020335916397646626,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0003966510928472775,-0.00013738983629066386,-3.7971221409699866e-05,-6.431763035574533e-05,-0.00011857739882295322,-9.359520863114822e-05,-5.0878371516215046e-05,-8.269367595092908e-08,0.0,1.3434539131099211e-05,-1.9601690213728576e-06,-2.8527045990494954e-05,-7.410332699310603e-05,-7.132130570080122e-05,-4.9780961185536e-05,-6.641505361384578e-05,-6.962005514093816e-05,-7.752898158331023e-05,-0.00017393609499225025,-0.0012529479255443958,0.0,0.0,0.00020682521269893754,0.0,0.0,0.0,0.0,0.0,-0.00046702467383631055,-0.00010318036388792008,1.2004408785841247e-05,0.0,-2.5158639357650687e-05,-1.2095240910793449e-05,-5.19052816902203e-06,-4.916790639558058e-06,-8.48395853563783e-06,-9.362757097074547e-06,-2.0959335712838412e-05,-4.7790091043859085e-05,-7.92797600958695e-05,-4.462687041778011e-05,-4.182992428577707e-05,-3.7547996285851254e-05,-4.52754480225615e-05,-1.8553562561513456e-05,-0.00024763037962085644,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00034886180455242474,-5.687523659359091e-06,7.380040279654313e-05,4.395860636703821e-05,7.145198242379862e-05,6.181248343370637e-06,0.0,-6.0855538083486296e-05,-4.8563908323274725e-05,-4.117920588930435e-05,-4.359283623112936e-05,-6.608754161500044e-05,-5.443032251266018e-05,-2.7782637880987207e-05,0.0,0.0,0.0002879461393464088,-0.0028955529777851255,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00012312114837837392,-1.9526747917254753e-05,-1.6999506829961688e-05,5.4835294148085086e-05,1.523441632762399e-05,-5.8365604525328614e-05,-0.00012378194216521848,-0.00011750704953254656,-6.19711523061306e-05,-5.042009645812091e-05,-0.00014055260223565886,-0.0001410330942465528,-0.00019272308238929396,-0.0004802489964676616]\n",
      "Intercept: 0.0129113052145\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(training)\n",
    "\n",
    "print lsvcModel.numFeatures\n",
    "print lsvcModel.numClasses\n",
    "\n",
    "# Print the coefficients and intercept for linear SVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier\n",
    "- Supports both binary and multiclass labels, as well as both continuous and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "(692,[322,407],[0.05149051490514917,0.9485094850948508])\n",
      "692\n",
      "2\n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_102e099841c9) of depth 2 with 5 nodes\n",
      "  If (feature 407 <= 83.0)\n",
      "   If (feature 322 <= 253.5)\n",
      "    Predict: 1.0\n",
      "   Else (feature 322 > 253.5)\n",
      "    Predict: 0.0\n",
      "  Else (feature 407 > 83.0)\n",
      "   Predict: 0.0\n",
      "\n",
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|(692,[121,122,123...|\n",
      "|       1.0|         1.0|(692,[123,124,125...|\n",
      "|       1.0|         1.0|(692,[124,125,126...|\n",
      "|       1.0|         1.0|(692,[124,125,126...|\n",
      "|       1.0|         1.0|(692,[126,127,128...|\n",
      "|       1.0|         1.0|(692,[127,128,129...|\n",
      "|       1.0|         1.0|(692,[155,156,180...|\n",
      "|       1.0|         1.0|(692,[234,235,237...|\n",
      "|       1.0|         0.0|(692,[97,98,99,12...|\n",
      "|       0.0|         0.0|(692,[100,101,102...|\n",
      "|       0.0|         0.0|(692,[123,124,125...|\n",
      "|       0.0|         0.0|(692,[123,124,125...|\n",
      "|       0.0|         0.0|(692,[124,125,126...|\n",
      "|       1.0|         0.0|(692,[124,125,126...|\n",
      "|       1.0|         0.0|(692,[124,125,126...|\n",
      "|       0.0|         0.0|(692,[127,128,154...|\n",
      "|       0.0|         0.0|(692,[128,129,130...|\n",
      "|       0.0|         0.0|(692,[128,129,130...|\n",
      "|       0.0|         0.0|(692,[129,130,131...|\n",
      "|       0.0|         0.0|(692,[129,130,131...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Error = 0.125 \n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_102e099841c9) of depth 2 with 5 nodes\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "dt_model = model.stages[2]\n",
    "print dt_model.numNodes\n",
    "print dt_model.depth\n",
    "print dt_model.featureImportances\n",
    "print dt_model.numFeatures\n",
    "print dt_model.numClasses\n",
    "print dt_model.toDebugString\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(20)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier\n",
    "- Supports both binary and multiclass labels, as well as both continuous and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           0.0|  0.0|(692,[95,96,97,12...|\n",
      "|           0.0|  0.0|(692,[122,123,148...|\n",
      "|           0.0|  0.0|(692,[123,124,125...|\n",
      "|           0.0|  0.0|(692,[124,125,126...|\n",
      "|           0.0|  0.0|(692,[124,125,126...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_bcab066a1ecf) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "pyspark.ml.clustering module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means\n",
    "- The MLlib implementation includes a parallelized variant of the [k-means++](http://en.wikipedia.org/wiki/K-means%2B%2B) method called [kmeans||](http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf) (pronounced. as. KMeans. Parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.999753030538\n",
      "Cluster Centers: \n",
      "[0.1 0.1 0.1]\n",
      "[9.1 9.1 9.1]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(dataset)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(dataset)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bisecting K-means\n",
    "- Bisecting k-means is a kind of hierarchical clustering using a divisive (or “top-down”) approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n",
    "- Bisecting K-means can often be much faster than regular K-means, but it will generally produce a different clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 0.12\n",
      "Cluster Centers: \n",
      "[0.1 0.1 0.1]\n",
      "[9.1 9.1 9.1]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "# Trains a bisecting k-means model.\n",
    "bkm = BisectingKMeans().setK(2).setSeed(1)\n",
    "model = bkm.fit(dataset)\n",
    "\n",
    "# Evaluate clustering.\n",
    "cost = model.computeCost(dataset)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(cost))\n",
    "\n",
    "# Shows the result.\n",
    "print(\"Cluster Centers: \")\n",
    "centers = model.clusterCenters()\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Mixture Model (GMM)\n",
    "- This implementation uses the expectation-maximization algorithm to induce the maximum-likelihood model given a set of samples.\n",
    "- For high-dimensional data (with many features), this algorithm may perform poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussians shown as a DataFrame: \n",
      "+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|mean                                                         |cov                                                                                                                                                                                                     |\n",
      "+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[0.10000000000001552,0.10000000000001552,0.10000000000001552]|0.006666666666806454  0.006666666666806454  0.006666666666806454  \n",
      "0.006666666666806454  0.006666666666806454  0.006666666666806454  \n",
      "0.006666666666806454  0.006666666666806454  0.006666666666806454  |\n",
      "|[9.099999999999984,9.099999999999984,9.099999999999984]      |0.006666666666812185  0.006666666666812185  0.006666666666812185  \n",
      "0.006666666666812185  0.006666666666812185  0.006666666666812185  \n",
      "0.006666666666812185  0.006666666666812185  0.006666666666812185  |\n",
      "+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "# loads data\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "gmm = GaussianMixture().setK(2).setSeed(538009335)\n",
    "model = gmm.fit(dataset)\n",
    "\n",
    "print(\"Gaussians shown as a DataFrame: \")\n",
    "model.gaussiansDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (잠재 디리클레 할당)\n",
    "- a topic modeling angorithm for text documents.\n",
    "- Terminology:\n",
    "  - “term” = “word”: an element of the vocabulary\n",
    "  - “token”: instance of a term appearing in a document\n",
    "  - “topic”: multinomial distribution over terms representing some concept\n",
    "  - “document”: one piece of text, corresponding to one row in the input data\n",
    "- Original LDA paper (journal version): Blei, Ng, and Jordan. “Latent Dirichlet Allocation.” JMLR, 2003.\n",
    "- Input data (featuresCol): LDA is given a collection of documents as input data, via the featuresCol parameter. Each document is specified as a Vector of length vocabSize, where each entry is the count for the corresponding term (word) in the document. Feature transformers such as pyspark.ml.feature.Tokenizer and pyspark.ml.feature.CountVectorizer can be useful for converting text to word count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -793.702520879\n",
      "The upper bound on perplexity: 3.05270200338\n",
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------+---------------------------------------------------------------+\n",
      "|topic|termIndices|termWeights                                                    |\n",
      "+-----+-----------+---------------------------------------------------------------+\n",
      "|0    |[4, 7, 10] |[0.10776277938911112, 0.09745723998107463, 0.09621597542482398]|\n",
      "|1    |[1, 9, 6]  |[0.19441066201641036, 0.15183608184852107, 0.13010666150332537]|\n",
      "|2    |[1, 3, 9]  |[0.10061328637416841, 0.10041201526106697, 0.099088247685484]  |\n",
      "|3    |[1, 3, 7]  |[0.10154019643706694, 0.09971532009948404, 0.0989987650422771] |\n",
      "|4    |[9, 10, 3] |[0.10475334419062468, 0.10203711274001848, 0.0981609559238797] |\n",
      "|5    |[8, 5, 7]  |[0.10837749937143021, 0.09699499254080268, 0.0933369868267339] |\n",
      "|6    |[8, 5, 0]  |[0.09871687108232934, 0.09652500816785077, 0.09564466649588127]|\n",
      "|7    |[9, 4, 7]  |[0.11245351226473149, 0.09752895346336911, 0.0964160619065042] |\n",
      "|8    |[4, 0, 5]  |[0.16460836829994308, 0.15658440512526928, 0.14231192756892774]|\n",
      "|9    |[3, 4, 10] |[0.25688376703539617, 0.098417800298997, 0.09640300181083226]  |\n",
      "+-----+-----------+---------------------------------------------------------------+\n",
      "\n",
      "+-----+---------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                       |topicDistribution                                                                                                                                                                                                   |\n",
      "+-----+---------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |(11,[0,1,2,4,5,6,7,10],[1.0,2.0,6.0,2.0,3.0,1.0,1.0,3.0])      |[0.004776313193465123,0.9566551024223149,0.004776291497259786,0.004776325208648256,0.00477630415360795,0.004776327234056339,0.004776363477151123,0.004776309380573367,0.00495981213689097,0.0049508512960322335]    |\n",
      "|1.0  |(11,[0,1,3,4,7,10],[1.0,3.0,1.0,3.0,2.0,1.0])                  |[0.007968429503963499,0.008776106300429954,0.007968451734031275,0.007968541496421662,0.007968450898193492,0.00796840918251131,0.007968422397061534,0.007968405948762004,0.9271836722746482,0.008261110263977158]    |\n",
      "|2.0  |(11,[0,1,2,5,6,8,9],[1.0,4.0,1.0,4.0,9.0,1.0,2.0])             |[0.004152304156798777,0.9623178943758289,0.004152391395912797,0.004152332933005872,0.004152366250773946,0.004152381517986736,0.004152394756559637,0.004152344471508035,0.00431156120663884,0.004304028934986579]    |\n",
      "|3.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,3.0,9.0])            |[0.0036727860442300163,0.6052030464242353,0.003672809027861601,0.003672807841274835,0.003672880954156445,0.0036728318037214467,0.0036728597582978036,0.0036727743292687097,0.0038132738295876155,0.3652739299873664]|\n",
      "|4.0  |(11,[0,1,2,3,4,6,9,10],[3.0,1.0,1.0,9.0,3.0,2.0,1.0,3.0])      |[0.003979168594919918,0.0043823109185958135,0.003979197246178554,0.003979171703545142,0.0039791970390247915,0.00397916963778374,0.003979196550710718,0.0039791981733941694,0.004131812867268727,0.9636315772685784] |\n",
      "|5.0  |(11,[0,1,3,4,5,6,7,8,9],[4.0,2.0,3.0,4.0,5.0,1.0,1.0,1.0,4.0]) |[0.0036727853935160258,0.18028312413799577,0.0036728793776343773,0.0036728056372140713,0.003672858001884761,0.003672829369158372,0.0036728431377796634,0.003672863795561659,0.6800119000746682,0.11399511107458711] |\n",
      "|6.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,2.0,9.0])            |[0.0038198779672105336,0.5525733056959493,0.0038198985384478887,0.0038199023256759736,0.0038199752324361417,0.0038199289043503175,0.0038199567413733536,0.0038198575370196,0.003965998937813642,0.41672129811972325]|\n",
      "|7.0  |(11,[0,1,2,3,4,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,1.0,2.0,1.0,3.0])|[0.004341381281263326,0.004781282654470298,0.00434142793147297,0.004341409014135537,0.00434142854478484,0.004341395827925647,0.004341422773932791,0.0043414189320846635,0.004507776440055645,0.9603210565998743]    |\n",
      "|8.0  |(11,[0,1,3,4,5,6,7],[4.0,4.0,3.0,4.0,2.0,1.0,3.0])             |[0.004341389435034175,0.004780905822439902,0.004341506514492227,0.004341478599591156,0.0043414411345632925,0.004341420895270371,0.004341436059882918,0.004341465889162206,0.9603278308544262,0.004501124795137465]  |\n",
      "|9.0  |(11,[0,1,2,4,6,8,9,10],[2.0,8.0,2.0,3.0,2.0,2.0,7.0,2.0])      |[0.003292367566793614,0.9701219828745324,0.003292384432223619,0.003292358874741075,0.003292367019309872,0.003292378151931468,0.003292376273690569,0.003292375895892758,0.0034187851512227038,0.0034126237596618404] |\n",
      "|10.0 |(11,[0,1,2,3,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,2.0,3.0,3.0])      |[0.00415241190991309,0.004574056034379942,0.004152496622223037,0.004152435515319234,0.004152504560680503,0.004152450276472498,0.0041524908645246385,0.004152491045904028,0.004311510181383191,0.9620471529891998]   |\n",
      "|11.0 |(11,[0,1,4,5,6,7,9],[4.0,1.0,4.0,5.0,1.0,3.0,1.0])             |[0.004776105673991563,0.0052599985212639306,0.004776144641974715,0.0047760876089693845,0.004776129586291701,0.00477612654705738,0.004776140957219011,0.004776155457134568,0.9563565467804249,0.004950564225672841]  |\n",
      "+-----+---------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/sample_lda_libsvm_data.txt\")\n",
    "\n",
    "# Trains a LDA model.\n",
    "lda = LDA(k=10, maxIter=10)\n",
    "model = lda.fit(dataset)\n",
    "\n",
    "ll = model.logLikelihood(dataset)\n",
    "lp = model.logPerplexity(dataset)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n",
    "\n",
    "# Describe topics.\n",
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)\n",
    "\n",
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation\n",
    "pyspark.ml.recommendation module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.82781455763\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                                                                                                         |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|12    |[[33, 5.4997563], [27, 5.275545], [35, 4.987362], [64, 4.946457], [17, 4.9319854], [90, 4.7610598], [32, 4.2833667], [94, 4.154465], [16, 3.9035554], [20, 3.8659265]]  |\n",
      "|13    |[[81, 4.372699], [32, 4.2185254], [93, 3.9821076], [92, 3.9535875], [55, 3.9106627], [96, 3.8878133], [38, 3.4557033], [30, 3.2873852], [53, 3.126037], [69, 3.1253324]]|\n",
      "|14    |[[52, 5.049337], [63, 5.009508], [58, 4.052312], [70, 4.016981], [96, 4.002898], [62, 3.831398], [72, 3.780383], [85, 3.602288], [43, 3.5845509], [87, 3.571566]]       |\n",
      "|25    |[[94, 4.23306], [33, 4.0221744], [71, 3.8974257], [40, 3.574299], [47, 3.4902976], [62, 3.125086], [34, 3.0672412], [57, 3.0534465], [16, 3.046286], [90, 2.934964]]    |\n",
      "|18    |[[28, 4.950815], [38, 4.942483], [39, 4.93263], [2, 4.246412], [59, 4.172325], [96, 4.096461], [53, 3.9307046], [29, 3.8494349], [52, 3.7746642], [18, 3.3253427]]      |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|movieId|recommendations                                                                                                                                                      |\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|50     |[[11, 4.148935], [23, 4.1039057], [12, 3.7216263], [9, 2.7517152], [7, 2.42429], [5, 2.2431254], [29, 1.9851645], [15, 1.9519203], [8, 1.3164605], [16, 1.2813684]]  |\n",
      "|70     |[[16, 4.4075093], [8, 4.215828], [14, 4.016981], [7, 3.887699], [2, 3.5797467], [4, 3.4387012], [21, 3.426507], [26, 3.1195111], [9, 3.1192791], [24, 2.3725696]]    |\n",
      "|12     |[[28, 4.6971607], [10, 3.9262059], [12, 3.6253958], [8, 3.1342976], [2, 3.1036208], [25, 2.835409], [0, 2.3420305], [18, 1.7313843], [27, 1.6303828], [23, 1.324057]]|\n",
      "|52     |[[2, 5.697592], [14, 5.049337], [8, 4.995247], [24, 4.852968], [6, 4.692406], [16, 4.5199013], [11, 4.099862], [18, 3.7746642], [4, 3.6839588], [9, 3.4596283]]      |\n",
      "|13     |[[23, 4.034729], [11, 3.9522624], [24, 3.9095924], [16, 3.6917317], [9, 2.9080527], [26, 2.8913844], [29, 2.6640935], [3, 2.4371552], [17, 2.327794], [2, 2.2175522]]|\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|     2|\n",
      "|     4|\n",
      "|     5|\n",
      "+------+\n",
      "\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                                                                                                           |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2     |[[52, 5.697592], [8, 5.066208], [83, 4.970949], [72, 4.174289], [92, 4.0890055], [89, 4.045195], [53, 3.9408538], [34, 3.8086052], [40, 3.7789762], [70, 3.5797467]]      |\n",
      "|4     |[[29, 4.1007094], [52, 3.6839588], [70, 3.4387012], [53, 3.2735896], [63, 3.0124614], [60, 2.7514598], [72, 2.6923935], [59, 2.2973814], [40, 2.2573652], [58, 2.2118318]]|\n",
      "|5     |[[46, 4.8682666], [55, 4.860742], [49, 4.014814], [68, 3.870381], [62, 3.6156511], [32, 3.5947323], [23, 3.223452], [92, 3.1329796], [25, 3.1052494], [75, 2.9114027]]    |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+-------+\n",
      "|movieId|\n",
      "+-------+\n",
      "|      2|\n",
      "|      5|\n",
      "|     12|\n",
      "+-------+\n",
      "\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                                                                                                           |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2     |[[52, 5.697592], [8, 5.066208], [83, 4.970949], [72, 4.174289], [92, 4.0890055], [89, 4.045195], [53, 3.9408538], [34, 3.8086052], [40, 3.7789762], [70, 3.5797467]]      |\n",
      "|4     |[[29, 4.1007094], [52, 3.6839588], [70, 3.4387012], [53, 3.2735896], [63, 3.0124614], [60, 2.7514598], [72, 2.6923935], [59, 2.2973814], [40, 2.2573652], [58, 2.2118318]]|\n",
      "|5     |[[46, 4.8682666], [55, 4.860742], [49, 4.014814], [68, 3.870381], [62, 3.6156511], [32, 3.5947323], [23, 3.223452], [92, 3.1329796], [25, 3.1052494], [75, 2.9114027]]    |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "lines = spark.read.text(\"/opt/conda/envs/ml/lib/python2.7/site-packages/pyspark/data/mllib/als/sample_movielens_ratings.txt\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "                                     rating=float(p[2]), timestamp=long(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "#als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", implicitPrefs=True)\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.show(5, truncate=False)\n",
    "\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "movieRecs.show(5, truncate=False)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "users.show()\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "userSubsetRecs.show(5, truncate=False)\n",
    "\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movies.show()\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "userSubsetRecs.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent Pattern Mining\n",
    "pyspark.ml.fpm module\n",
    "\n",
    "- A parallel FP-growth algorithm to mine frequent itemsets.\n",
    "- The algorithm is described in Li et al., PFP: Parallel FP-Growth for Query Recommendation [LI2008](http://dx.doi.org/10.1145/1454008.1454027).\n",
    "- PFP distributes computation in such a way that each worker executes an independent group of mining tasks.\n",
    "- The FP-Growth algorithm is described in Han et al., Mining frequent patterns without candidate generation [HAN2000](http://dx.doi.org/10.1145/335191.335372)\n",
    "\n",
    "- Mining frequent items, itemsets, subsequences, or other substructures is usually among the first steps to analyze a large-scale dataset, which has been an active research topic in data mining for years. We refer users to Wikipedia’s association rule learning for more information.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|    items|freq|\n",
      "+---------+----+\n",
      "|      [1]|   3|\n",
      "|      [2]|   3|\n",
      "|   [2, 1]|   3|\n",
      "|      [5]|   2|\n",
      "|   [5, 2]|   2|\n",
      "|[5, 2, 1]|   2|\n",
      "|   [5, 1]|   2|\n",
      "+---------+----+\n",
      "\n",
      "+----------+----------+------------------+----+\n",
      "|antecedent|consequent|        confidence|lift|\n",
      "+----------+----------+------------------+----+\n",
      "|    [5, 2]|       [1]|               1.0| 1.0|\n",
      "|       [2]|       [1]|               1.0| 1.0|\n",
      "|       [2]|       [5]|0.6666666666666666| 1.0|\n",
      "|    [2, 1]|       [5]|0.6666666666666666| 1.0|\n",
      "|       [5]|       [2]|               1.0| 1.0|\n",
      "|       [5]|       [1]|               1.0| 1.0|\n",
      "|    [5, 1]|       [2]|               1.0| 1.0|\n",
      "|       [1]|       [2]|               1.0| 1.0|\n",
      "|       [1]|       [5]|0.6666666666666666| 1.0|\n",
      "+----------+----------+------------------+----+\n",
      "\n",
      "+---+------------+----------+\n",
      "| id|       items|prediction|\n",
      "+---+------------+----------+\n",
      "|  0|   [1, 2, 5]|        []|\n",
      "|  1|[1, 2, 3, 5]|        []|\n",
      "|  2|      [1, 2]|       [5]|\n",
      "+---+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (0, [1, 2, 5]),\n",
    "    (1, [1, 2, 3, 5]),\n",
    "    (2, [1, 2])\n",
    "], [\"id\", \"items\"])\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fpGrowth.fit(df)\n",
    "\n",
    "# Display frequent itemsets.\n",
    "model.freqItemsets.show()\n",
    "\n",
    "# Display generated association rules.\n",
    "model.associationRules.show()\n",
    "\n",
    "# transform examines the input items against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluators\n",
    "- pyspark.ml.evaluation module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegressionEvaluator\n",
    "- `rmse - root mean squared error`, `mse - mean squared error`, `r2 - r^2 metric`, `mae - mean absolute error`\n",
    "\n",
    "> RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.84248540819\n",
      "0.993911102599\n",
      "2.64964543\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "scoreAndLabels = [(-28.98343821, -27.0), (20.21491975, 21.5), (-25.98418959, -22.0), (30.69731842, 33.0), (74.69283752, 71.0)]\n",
    "dataset = spark.createDataFrame(scoreAndLabels, [\"raw\", \"label\"])\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"raw\")\n",
    "\n",
    "print evaluator.evaluate(dataset)\n",
    "print evaluator.evaluate(dataset, {evaluator.metricName: \"r2\"})\n",
    "print evaluator.evaluate(dataset, {evaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinaryClassificationEvaluator\n",
    "- `areaUnderROC`, `areaUnderPR`\n",
    "\n",
    "> BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='label', metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "dataset = spark.createDataFrame(scoreAndLabels, [\"raw\", \"label\"])\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"raw\")\n",
    "\n",
    "print evaluator.evaluate(dataset)\n",
    "print evaluator.evaluate(dataset, {evaluator.metricName: \"areaUnderPR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MulticlassClassificationEvaluator\n",
    "- `f1`, `weightedPrecision`, `weightedRecall`, `accuracy`\n",
    "\n",
    "> MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661375661376\n",
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "scoreAndLabels = [(0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (2.0, 2.0), (2.0, 0.0)]\n",
    "dataset = spark.createDataFrame(scoreAndLabels, [\"prediction\", \"label\"])\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "print  evaluator.evaluate(dataset)\n",
    "print evaluator.evaluate(dataset, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClusteringEvaluator\n",
    "- The metric computes the `Silhouette` measure using the `squared Euclidean` distance.\n",
    "- The Silhouette is a measure for the validation of the consistency within clusters. It ranges between 1 and -1, where a value close to 1 means that the points in a cluster are close to the other points in the same cluster and far from the points of the other clusters.\n",
    "\n",
    "> ClusteringEvaluator(predictionCol='prediction', featuresCol='features', metricName='silhouette', distanceMeasure='squaredEuclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907963385368\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "featureAndPredictions = map(lambda x: (Vectors.dense(x[0]), x[1]),\n",
    "                            [([0.0, 0.5], 0.0), ([0.5, 0.0], 0.0), ([10.0, 11.0], 1.0),\n",
    "                             ([10.5, 11.5], 1.0), ([1.0, 1.0], 0.0), ([8.0, 6.0], 1.0)])\n",
    "dataset = spark.createDataFrame(featureAndPredictions, [\"features\", \"prediction\"])\n",
    "\n",
    "evaluator = ClusteringEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "print evaluator.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "pyspark.ml.tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "output = ParamGridBuilder() \\\n",
    "        .baseOn({lr.labelCol: 'l'}) \\\n",
    "        .baseOn([lr.predictionCol, 'p']) \\\n",
    "        .addGrid(lr.regParam, [1.0, 2.0]) \\\n",
    "        .addGrid(lr.maxIter, [1, 5]) \\\n",
    "        .build()\n",
    "\n",
    "expected = [\n",
    "        {lr.regParam: 1.0, lr.maxIter: 1, lr.labelCol: 'l', lr.predictionCol: 'p'},\n",
    "        {lr.regParam: 2.0, lr.maxIter: 1, lr.labelCol: 'l', lr.predictionCol: 'p'},\n",
    "        {lr.regParam: 1.0, lr.maxIter: 5, lr.labelCol: 'l', lr.predictionCol: 'p'},\n",
    "        {lr.regParam: 2.0, lr.maxIter: 5, lr.labelCol: 'l', lr.predictionCol: 'p'}]\n",
    "\n",
    "assert(len(output)==len(expected))\n",
    "assert(all([m in expected for m in output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "pyspark.ml.tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.833333333333\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "dataset = spark.createDataFrame(\n",
    "     [(Vectors.dense([0.0]), 0.0),\n",
    "      (Vectors.dense([0.4]), 1.0),\n",
    "      (Vectors.dense([0.5]), 0.0),\n",
    "      (Vectors.dense([0.6]), 1.0),\n",
    "      (Vectors.dense([1.0]), 1.0)] * 10,\n",
    "     [\"features\", \"label\"])\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2)\n",
    "cvModel = cv.fit(dataset)\n",
    "\n",
    "print cvModel.avgMetrics[0]\n",
    "print evaluator.evaluate(cvModel.transform(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "pyspark.ml.Pipeline and pyspark.ml.PipelineModel\n",
    "\n",
    "\n",
    "- `Transformer` : Abstract class for transformers that `transform one dataset into another`.\n",
    "\n",
    "- `UnaryTransformer` : Abstract class for transformers that `take one input column, apply transformation, and output the result as a new column`.\n",
    "\n",
    "- `Estimator` : Abstract class for estimators that `fit models to data`.\n",
    "\n",
    "- `Model` : Abstract class for `models that are fitted by estimators`.\n",
    "\n",
    "- `Pipeline` : A simple pipeline, which `acts as an estimator`. A Pipeline consists of a sequence of stages, each of which is either an Estimator or a Transformer. When Pipeline.fit() is called, the stages are executed in order. The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages. If stages is an empty list, the pipeline acts as an identity transformer.\n",
    "  - If a stage is an `Estimator`, its `Estimator.fit()` method will be called on the input dataset to fit a model. Then the model, which is a transformer, will be used to transform the dataset as the input to the next stage. \n",
    "  - If a stage is a `Transformer`, its `Transformer.transform()` method will be called to produce the dataset for the next stage. \n",
    "\n",
    "- `PipelineModel` : Represents `a compiled pipeline with transformers and fitted models`.\n",
    "\n",
    "- `DAG Pipelines`: A Pipeline’s stages are specified as an ordered array. The examples given here are all for linear Pipelines, i.e., Pipelines in which each stage uses data produced by the previous stage. It is possible to create non-linear Pipelines as long as the data flow graph forms a Directed Acyclic Graph (DAG). This graph is currently specified implicitly based on the input and output column names of each stage (generally specified as parameters). If the Pipeline forms a DAG, then the stages must be specified in topological order.\n",
    "\n",
    "- `Runtime checking`: Since Pipelines can operate on DataFrames with varied types, they cannot use compile-time type checking. Pipelines and PipelineModels instead do runtime checking before actually running the Pipeline. This type checking is done using the DataFrame schema, a description of the data types of columns in the DataFrame.\n",
    "\n",
    "- `Unique Pipeline stages`: A Pipeline’s stages should be unique instances. E.g., the same instance myHashingTF should not be inserted into the Pipeline twice since Pipeline stages must have unique IDs. However, different instances myHashingTF1 and myHashingTF2 (both of type HashingTF) can be put into the same Pipeline since different instances will be created with different IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, spark i j k) --> prob=[0.15964077387874745,0.8403592261212527], prediction=1.000000\n",
      "(5, l m n) --> prob=[0.8378325685476744,0.16216743145232562], prediction=0.000000\n",
      "(6, spark hadoop spark) --> prob=[0.06926633132976037,0.9307336686702395], prediction=1.000000\n",
      "(7, apache hadoop) --> prob=[0.9821575333444218,0.01784246665557808], prediction=0.000000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n",
    "\n",
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(training)\n",
    "\n",
    "# Prepare test documents, which are unlabeled (id, text) tuples.\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"spark hadoop spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents and print columns of interest.\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    rid, text, prob, prediction = row\n",
    "    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://spark.apache.org/docs/latest/ml-guide.html\n",
    "- https://www.wikipedia.org/\n",
    "- https://stattrek.com/chi-square-test/goodness-of-fit.aspx\n",
    "- https://towardsdatascience.com/inferential-statistic-understanding-hypothesis-testing-using-chi-square-test-eacf9fcac533\n",
    "- https://en.wikipedia.org/wiki/Generalized_linear_model#Model_components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
